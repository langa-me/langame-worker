{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('.venv': venv)"
  },
  "interpreter": {
   "hash": "2ca8946d339ea3bbaa73adc6693d06c322e424e77befb9c6b521a96205a94f7d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from langame_client import LangameClient\n",
    "from pprint import pprint\n",
    "from firebase_admin import firestore\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import openai\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import markdown\n",
    "c = LangameClient()\n",
    "READWISE_TOKEN=\"grab me here https://readwise.io/access_token\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "out_file_name = \"data/brain-0.0.1.jsonl\"\n",
    "count_file = 0\n",
    "for p in Path(\"../brain\").rglob(\"*.[mM][dD]\"):\n",
    "  count_file += 1\n",
    "  with open(p) as f:\n",
    "    lines = \"\".join(f.readlines())\n",
    "    with open(out_file_name, \"a+\") as outfile:\n",
    "      json.dump({\n",
    "          \"prompt\": f\"{str(p.stem)}:\",\n",
    "          \"completion\": f\" {lines}\\n###\\n\",\n",
    "      }, outfile)\n",
    "      outfile.write('\\n')\n",
    "print(\"found\", count_file, \"files\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "found 657 files\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def get_all_highlights():\n",
    "  highlights = []\n",
    "  page = 1\n",
    "  url = f\"https://readwise.io/api/v2/highlights/\"\n",
    "  while url:\n",
    "    response = requests.get(\n",
    "        url=url,\n",
    "        headers={\"Authorization\": f\"Token {READWISE_TOKEN}\"},\n",
    "    ).json()\n",
    "    if \"results\" in response:\n",
    "      highlights = highlights + response[\"results\"]\n",
    "\n",
    "    url = response[\"next\"] if \"next\" in response else None\n",
    "    page += 1\n",
    "  return highlights\n",
    "highlights = get_all_highlights()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "out_file_name = \"data/readwise-0.0.1.jsonl\"\n",
    "count_file = 0\n",
    "df = pd.DataFrame(highlights)\n",
    "with open(out_file_name, \"a+\") as outfile:\n",
    "  for i, v in df.iterrows():\n",
    "    prompt = ','.join([e['name'] for e in v['tags']])\n",
    "    if prompt: prompt += \":\"\n",
    "    json.dump({\n",
    "        \"prompt\": f\"{prompt}\",\n",
    "        \"completion\": f\" {v.text}\\n###\\n\",\n",
    "    }, outfile)\n",
    "    outfile.write('\\n')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "memes = []\n",
    "for e in c._firestore_client.collection('memes').stream():\n",
    "    memes.append((e.id, e.to_dict()))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "memes[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('0FNnecFpEToBI1mwAIJF',\n",
       " {'topics': ['health'],\n",
       "  'createdAt': DatetimeWithNanoseconds(2021, 7, 6, 9, 1, 3, 85000, tzinfo=<UTC>),\n",
       "  'content': 'Do you have any type of disability or chronic illness?',\n",
       "  'translated': {'de': 'Haben Sie eine Behinderung oder eine chronische Krankheit?',\n",
       "   'es': '¿Tiene algún tipo de discapacidad o enfermedad crónica?',\n",
       "   'fr': 'Avez-vous un type de handicap ou de maladie chronique?'}})"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "file_name = 'data/memes-0.0.1.jsonl'\n",
    "with open(file_name, 'a+') as outfile:\n",
    "    for meme in memes:\n",
    "        prompt = ','.join([e for e in meme[1]['topics']])\n",
    "        if prompt: prompt += \":\"\n",
    "        json.dump({\n",
    "            \"prompt\": f\"{prompt}\",\n",
    "            \"completion\": f\" {meme[1]['content']}\\n###\\n\"\n",
    "        }, outfile)\n",
    "        outfile.write('\\n')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "file_name = 'data/brain-0.0.1-readwise-0.0.1-memes-0.0.1.jsonl'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "data = data2 = data3 = \"\"\n",
    "  \n",
    "with open('data/brain-0.0.1.jsonl') as fp:\n",
    "    data = fp.read()\n",
    "  \n",
    "with open('data/readwise-0.0.1.jsonl') as fp:\n",
    "    data2 = fp.read()\n",
    "\n",
    "with open('data/memes-0.0.1.jsonl') as fp:\n",
    "    data3 = fp.read()\n",
    "  \n",
    "data += data2\n",
    "data += data3\n",
    "\n",
    "with open (file_name, 'w') as fp:\n",
    "    fp.write(data)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "!openai tools fine_tunes.prepare_data -f $file_name"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Analyzing...\n",
      "\n",
      "- Your file contains 3163 prompt-completion pairs\n",
      "- There are 8 duplicated prompt-completion pairs. These are rows: [733, 1249, 1263, 1319, 2064, 3065, 3069, 3089]\n",
      "- There are 6 examples that are very long. These are rows: [27, 31, 41, 45, 46, 338]\n",
      "For conditional generation, and for classification the examples shouldn't be longer than 2048 tokens.\n",
      "- Your data does not contain a common separator at the end of your prompts. Having a separator string appended to the end of the prompt makes it clearer to the fine-tuned model where the completion should begin. See https://beta.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples. If you intend to do open-ended generation, then you should leave the prompts empty\n",
      "- All completions end with suffix `\\n###\\n`\n",
      "\n",
      "Based on the analysis we will perform the following actions:\n",
      "- [Recommended] Remove 8 duplicate rows [Y/n]: ^C\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "f = openai.File.create(\n",
    "  file=open(file_name),\n",
    "  purpose=\"fine-tune\"\n",
    ")\n",
    "f_t = openai.FineTune.create(\n",
    "    training_file=f[\"id\"],\n",
    "    model=\"curie\"\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Upload progress: 100%|██████████| 1.30M/1.30M [00:01<00:00, 1.28Mit/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "model = openai.FineTune.list()['data'][-1]\n",
    "model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "p = {}\n",
    "p[\"type\"] = file_name\n",
    "p[\"template\"] = \"\"\"This is a conversation starter about [TOPIC].\n",
    "Conversation starter:\"\"\"\n",
    "p[\"parameters\"] = {\n",
    "    \"model\": model[\"fine_tuned_model\"],\n",
    "    \"temperature\": 0.7,\n",
    "    \"maxTokens\": 150,\n",
    "    \"topP\": 1,\n",
    "    \"frequencyPenalty\": 0.1,\n",
    "    \"presencePenalty\": 0.1,\n",
    "    \"stop\": [\"\\n###\\n\", \"###\", \"\\n\", \"Conversation starter\", \"starter\"],\n",
    "}\n",
    "p_col = c._firestore_client.collection(\"prompts\")\n",
    "new_prompt_ref = p_col.add(p)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "openai.Completion.create(\n",
    "  model=model[\"fine_tuned_model\"],\n",
    "  prompt=\"\",\n",
    "  max_tokens=300,\n",
    "  stop=[\"\\n###\\n\", \"###\"],\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-3bb9PbAkCra9NSEJrOTKDhDxi4yCP at 0x13f15c770> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"While most of humanity is focused on avoiding harm, a small but very vocal minority has decided that the best way to avoid harm is to actively seeks it out. Called \\u201cthe optimists\\u201d by the media, this group includes anarchists, Daredevil bloggers, thrill-seekers, and other \\u2013 sometimes bizarre \\u2013 personalities.\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1630089955,\n",
       "  \"id\": \"cmpl-3bb9PbAkCra9NSEJrOTKDhDxi4yCP\",\n",
       "  \"model\": \"curie:ft-louis-personal-2021-08-27-16-57-14\",\n",
       "  \"object\": \"text_completion\"\n",
       "}"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}