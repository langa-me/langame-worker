{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langame_client import LangameClient\n",
    "from pprint import pprint\n",
    "from firebase_admin import firestore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "langame_client = LangameClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(DatetimeWithNanoseconds(2021, 7, 16, 15, 49, 26, 906587, tzinfo=datetime.timezone.utc),\n <google.cloud.firestore_v1.document.DocumentReference object at 0x7f4c13177610>)\n"
     ]
    }
   ],
   "source": [
    "# TODO: use protobuf\n",
    "p = {}\n",
    "p[\"type\"] = \"TopicGeneralist\"\n",
    "p[\"template\"] = \"\"\"This is a conversation starter that leads to extremely profound conversations between people about \"[TOPIC]\".\n",
    "Starter: What do you think of the theory that animals have emotions?\n",
    "Starter: What is the role of philosophy in human society?\n",
    "Starter: How does one recognize truth and knowledge? What are the ways to acquire it?\n",
    "Starter:\"\"\"\n",
    "t = {\n",
    "    \"createdAt\": firestore.SERVER_TIMESTAMP,\n",
    "    \"engine\": {\n",
    "        \"parameters\": {\n",
    "            \"model\": \"davinci\",\n",
    "            \"temperature\": 0.7,\n",
    "            \"maxTokens\": 150,\n",
    "            \"topP\": 1,\n",
    "            \"frequencyPenalty\": 0.1,\n",
    "            \"presencePenalty\": 0.1,\n",
    "            \"stop\": [\"\\\\n\", \"Starter:\"],\n",
    "        }\n",
    "    }\n",
    "}\n",
    "p_col = langame_client._firestore_client.collection(\"prompts\")\n",
    "new_prompt_ref = p_col.add(p)\n",
    "pprint(p_col.document(new_prompt_ref[1].id).collection(\"tags\").add(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "calling openai with {'id': '4IpLQkq4VwnV4M3HheIg', 'prompt': 'It is a question that leads to extremely profound conversations between people about \"transhumanism\":\\n1.', 'parameters': {'temperature': 0.7, 'topP': 1, 'stop': ['\\\\n', '2.'], 'presencePenalty': 0.1, 'model': 'davinci', 'frequencyPenalty': 0.1, 'maxTokens': 150}}\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(DatetimeWithNanoseconds(2021, 7, 16, 15, 50, 4, 77231, tzinfo=datetime.timezone.utc),\n",
       " <google.cloud.firestore_v1.document.DocumentReference at 0x7f4c88307730>)"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "langame_client.prompt_to_meme(topic_with_emoji = \n",
    "    (\"transhumanism\", \"ü§îüß†üí≠üìöüìñüìêüß¨ü§ñü¶æü¶ø\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "calling openai with {'id': '4IpLQkq4VwnV4M3HheIg', 'prompt': 'It is a question that leads to extremely profound conversations between people about \"politic\":\\n1.', 'parameters': {'model': 'davinci', 'topP': 1, 'stop': ['\\\\n', '2.'], 'frequencyPenalty': 0.1, 'presencePenalty': 0.1, 'maxTokens': 150, 'temperature': 0.7}}\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(DatetimeWithNanoseconds(2021, 7, 16, 15, 50, 58, 292063, tzinfo=datetime.timezone.utc),\n",
       " <google.cloud.firestore_v1.document.DocumentReference at 0x7f4c13177250>)"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "langame_client.prompt_to_meme(topic_with_emoji = \n",
    "    (\"politic\", \"ü§îüí≠üìúüèõüë®üë©‚öñüóΩ\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "calling openai with {'id': '4IpLQkq4VwnV4M3HheIg', 'prompt': 'It is a question that leads to extremely profound conversations between people about \"mind\":\\n1.', 'parameters': {'maxTokens': 150, 'temperature': 0.7, 'model': 'davinci', 'stop': ['\\\\n', '2.'], 'frequencyPenalty': 0.1, 'presencePenalty': 0.1, 'topP': 1}}\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(DatetimeWithNanoseconds(2021, 7, 16, 15, 50, 29, 41695, tzinfo=datetime.timezone.utc),\n",
       " <google.cloud.firestore_v1.document.DocumentReference at 0x7f4c13e6d3a0>)"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "langame_client.prompt_to_meme(topic_with_emoji = \n",
    "    (\"mind\", \"ü§îüß†üí≠üìöüìñ\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'content': '\"If money is the root of all evil, what is the root of money?\"',\n",
      " 'createdAt': DatetimeWithNanoseconds(2021, 7, 7, 20, 20, 53, 806000, tzinfo=<UTC>),\n",
      " 'promptId': '4IpLQkq4VwnV4M3HheIg',\n",
      " 'translated': {'de': '\"Wenn Geld die Wurzel allen √úbels ist, was ist dann die '\n",
      "                      'Wurzel des Geldes?\"',\n",
      "                'es': '\"Si el dinero es la ra√≠z de todos los males, ¬øcu√°l es '\n",
      "                      'la ra√≠z del dinero?\"',\n",
      "                'fr': \"¬´ Si l'argent est la racine de tous les maux, quelle \"\n",
      "                      \"est la racine de l'argent ?\"}}\n",
      "{'content': '\"Are we talking about a \"state\" or a \"government\"?\"',\n",
      " 'createdAt': DatetimeWithNanoseconds(2021, 7, 7, 20, 19, 57, 328000, tzinfo=<UTC>),\n",
      " 'promptId': '4IpLQkq4VwnV4M3HheIg',\n",
      " 'translated': {'de': '\"Reden wir von einem \"Staat\" oder einer \"Regierung\"?\"',\n",
      "                'es': '\"¬øEstamos hablando de un\" estado \"o un\" gobierno \"?\"',\n",
      "                'fr': \"¬´ Parlons-nous d'un ¬´ √âtat ¬ª ou d'un ¬´ gouvernement ¬ª \"\n",
      "                      '?'}}\n",
      "{'content': '\"Cynicism vs. idealism\"',\n",
      " 'createdAt': DatetimeWithNanoseconds(2021, 7, 7, 20, 9, 1, 341000, tzinfo=<UTC>),\n",
      " 'promptId': 'elmPKsEuVytQrgS6RWTF',\n",
      " 'translated': {'de': '\"Zynismus vs. Idealismus\"',\n",
      "                'es': '\"Cinismo vs idealismo\"',\n",
      "                'fr': '\"Cynisme contre id√©alisme\"'}}\n",
      "{'content': '\"What\\'s your favorite book?\"\\n'\n",
      "            '\\n'\n",
      "            'Deep conversations about books are often sparked by this '\n",
      "            'question.',\n",
      " 'createdAt': DatetimeWithNanoseconds(2021, 7, 7, 15, 25, 50, 249000, tzinfo=<UTC>),\n",
      " 'promptId': 'uv5MS4pDr3AF5Qgbo1gi',\n",
      " 'translated': {'de': '\"Was ist dein Lieblingsbuch?\"\\n'\n",
      "                      '\\n'\n",
      "                      'Durch diese Frage werden oft tiefe Gespr√§che √ºber '\n",
      "                      'B√ºcher entz√ºndet.',\n",
      "                'es': '\"¬øCu√°l es tu libro favorito?\"\\n'\n",
      "                      '\\n'\n",
      "                      'Esta pregunta a menudo suscita conversaciones profundas '\n",
      "                      'sobre libros.',\n",
      "                'fr': '¬´\\xa0Quel est votre livre pr√©f√©r√©\\xa0?\\xa0¬ª\\n'\n",
      "                      '\\n'\n",
      "                      'Des conversations profondes sur les livres sont souvent '\n",
      "                      'd√©clench√©es par cette question.'}}\n",
      "{'content': \"I'm not sure if you're like me, but I've heard it's hard to start \"\n",
      "            \"a conversation with strangers or people you don't know.\\n\"\n",
      "            \"Well, I'm not sure if this is the best idea in the world, but \"\n",
      "            'what do you think if we try to start a conversation about the '\n",
      "            'weather?',\n",
      " 'createdAt': DatetimeWithNanoseconds(2021, 7, 7, 8, 2, 56, 265000, tzinfo=<UTC>),\n",
      " 'promptId': 'uv5MS4pDr3AF5Qgbo1gi',\n",
      " 'translated': {'de': 'Ich bin mir nicht sicher, ob Sie wie ich sind, aber ich '\n",
      "                      'habe geh√∂rt, dass es schwierig ist, mit Fremden oder '\n",
      "                      'Unbekannten ins Gespr√§ch zu kommen.\\n'\n",
      "                      'Nun, ich bin mir nicht sicher, ob das die beste Idee '\n",
      "                      'der Welt ist, aber was denkst du, wenn wir versuchen, '\n",
      "                      'ein Gespr√§ch √ºber das Wetter zu beginnen?',\n",
      "                'es': 'No estoy seguro de si eres como yo, pero he o√≠do que es '\n",
      "                      'dif√≠cil iniciar una conversaci√≥n con extra√±os o '\n",
      "                      'personas que no conoces.\\n'\n",
      "                      'Bueno, no estoy seguro si esta es la mejor idea del '\n",
      "                      'mundo, pero ¬øqu√© piensas si intentamos iniciar una '\n",
      "                      'conversaci√≥n sobre el clima?',\n",
      "                'fr': \"Je ne sais pas si vous √™tes comme moi, mais j'ai \"\n",
      "                      \"entendu dire qu'il est difficile d'entamer une \"\n",
      "                      'conversation avec des inconnus ou des personnes que '\n",
      "                      'vous ne connaissez pas.\\n'\n",
      "                      \"Eh bien, je ne sais pas si c'est la meilleure id√©e au \"\n",
      "                      \"monde, mais que pensez-vous si nous essayons d'entamer \"\n",
      "                      'une conversation sur la m√©t√©o ?'}}\n",
      "{'content': 'If you could be absolutely certain of something, what would it '\n",
      "            'be?',\n",
      " 'createdAt': DatetimeWithNanoseconds(2021, 6, 15, 10, 3, 36, 206000, tzinfo=<UTC>)}\n",
      "{'content': 'What do you fantasize about?',\n",
      " 'createdAt': DatetimeWithNanoseconds(2021, 6, 15, 10, 3, 36, 206000, tzinfo=<UTC>)}\n",
      "{'content': 'What are your thoughts on religion, God or spirituality?',\n",
      " 'createdAt': DatetimeWithNanoseconds(2021, 6, 15, 10, 3, 34, 120000, tzinfo=<UTC>)}\n",
      "{'content': 'What is the most valuable thought that you have had today?',\n",
      " 'createdAt': DatetimeWithNanoseconds(2021, 6, 15, 10, 3, 34, 120000, tzinfo=<UTC>)}\n",
      "{'content': 'What kind of person are you when you are your true self?',\n",
      " 'createdAt': DatetimeWithNanoseconds(2021, 6, 15, 10, 3, 31, 997000, tzinfo=<UTC>)}\n"
     ]
    }
   ],
   "source": [
    "for t in langame_client._firestore_client.collection_group(u\"tags\")\\\n",
    "    .where(u\"topic.content\", u\"in\", [\"ice breaker\"])\\\n",
    "    .order_by(u\"createdAt\", direction=firestore.Query.DESCENDING)\\\n",
    "    .limit(10)\\\n",
    "    .stream():\n",
    "    pprint(t.reference.parent.parent.get().to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(DatetimeWithNanoseconds(2021, 7, 16, 15, 34, 18, 122873, tzinfo=datetime.timezone.utc),\n <google.cloud.firestore_v1.document.DocumentReference object at 0x7f4c131a0fd0>)\n"
     ]
    }
   ],
   "source": [
    "# TODO: use protobuf\n",
    "p = {}\n",
    "p[\"type\"] = \"IceBreakerGeneralist\"\n",
    "p[\"template\"] = \"\"\"This is conversation starters that leads to extremely personal discussions between people.\n",
    "Starter: What is an interesting fact that few people know about you?\n",
    "Starter: What is something that most people take for granted, but has a deeper meaning to you?\n",
    "Starter:\"\"\"\n",
    "t = {\n",
    "    \"createdAt\": firestore.SERVER_TIMESTAMP,\n",
    "    \"engine\": {\n",
    "        \"parameters\": {\n",
    "            \"model\": \"davinci\",\n",
    "            \"temperature\": 0.7,\n",
    "            \"maxTokens\": 150,\n",
    "            \"topP\": 1,\n",
    "            \"frequencyPenalty\": 0.1,\n",
    "            \"presencePenalty\": 0.1,\n",
    "            \"stop\": [\"\\\\n\", \"Starter:\"],\n",
    "        }\n",
    "    }\n",
    "}\n",
    "p_col = langame_client._firestore_client.collection(\"prompts\")\n",
    "new_prompt_ref = p_col.add(p)\n",
    "pprint(p_col.document(new_prompt_ref[1].id).collection(\"tags\").add(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "calling openai with {'id': 'oCccJ82pVND4znQx3zM5', 'prompt': 'This is conversation starters that leads to extremely personal discussions between people.\\nStarter: What is an interesting fact that few people know about you?\\nStarter: What is something that most people take for granted, but has a deeper meaning to you?\\nStarter:', 'parameters': {'temperature': 0.7, 'maxTokens': 150, 'frequencyPenalty': 0.1, 'model': 'davinci', 'presencePenalty': 0.1, 'stop': ['\\\\n', 'Starter:'], 'topP': 1}}\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(DatetimeWithNanoseconds(2021, 7, 16, 15, 35, 59, 312111, tzinfo=datetime.timezone.utc),\n",
       " <google.cloud.firestore_v1.document.DocumentReference at 0x7f4c131a0dc0>)"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "langame_client.prompt_to_meme_ice_breaker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'template': 'It is a question that leads to extremely profound conversations '\n             'between people about \"[TOPIC]\":\\n'\n             '1.',\n 'type': 'TopicGeneralist'}\n{'template': 'Provide me a conversation starter that brings extremely deeply '\n             'personal conversations between people, thus breaking the ice.\\n'\n             'Starter:',\n 'type': 'IceBreakerGeneralist'}\n{'template': 'This is a question that leads to extremely profound '\n             'conversations between people and allow them to break the ice:\\n'\n             '1.',\n 'type': 'IceBreakerGeneralist'}\n"
     ]
    }
   ],
   "source": [
    "for e in langame_client._firestore_client.collection(\"prompts\")\\\n",
    "        .limit(5)\\\n",
    "        .stream():\n",
    "    pprint(e.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'write'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2299/4061457524.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mcompletions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"topic\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"topic\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"content\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"meme\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"content\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompletions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"examples\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.8.11/lib/python3.8/pprint.py\u001b[0m in \u001b[0;36mpprint\u001b[0;34m(object, stream, indent, width, depth, compact, sort_dicts)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         compact=compact, sort_dicts=sort_dicts)\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m def pformat(object, indent=1, width=80, depth=None, *,\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.11/lib/python3.8/pprint.py\u001b[0m in \u001b[0;36mpprint\u001b[0;34m(self, object)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.11/lib/python3.8/pprint.py\u001b[0m in \u001b[0;36m_format\u001b[0;34m(self, object, stream, indent, allowance, context, level)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobjid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0m_dispatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'write'"
     ]
    }
   ],
   "source": [
    "\n",
    "completions = []\n",
    "topics = [\"philosophy\", \"physic\", \"mathematic\", \"biology\", \"transhumanism\", \"artificial intelligence\", \"book\"]\n",
    "for t in langame_client._firestore_client.collection_group(u\"tags\")\\\n",
    "    .where(u\"topic.content\", u\"in\", topics)\\\n",
    "    .order_by(u\"createdAt\", direction=firestore.Query.DESCENDING)\\\n",
    "    .stream():\n",
    "    completions.append({\"topic\": t.to_dict()[\"topic\"][\"content\"], \"meme\": t.reference.parent.parent.get().to_dict()[\"content\"]})\n",
    "pprint(len(completions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#{\"prompt\": \"<prompt text>\", \"completion\": \"<ideal generated text>\"}\n",
    "def get_prompt(topic):\n",
    "    return f\"\"\"This is a conversation starter that leads to extremely profound conversations between people about \"{topic}\".\n",
    "Starter:\"\"\"\n",
    "\n",
    "dataset = [{\"prompt\": get_prompt(e[\"topic\"]), \"completion\": f\" {e['meme']}\"} for e in completions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('output.jsonl', 'w') as outfile:\n",
    "    for entry in dataset:\n",
    "        json.dump(entry, outfile)\n",
    "        outfile.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Analyzing...\n",
      "\n",
      "- Your file contains 56 prompt-completion pairs. In general, we recommend having at least a few hundred examples. We've found that performance tends to linearly increase for every doubling of the number of examples\n",
      "\n",
      "ERROR in common_suffix validator: All prompts are identical: `This is a conversation starter that leads to extremely profound conversations between people about \"philosophy\".\n",
      "Starter:`\n",
      "Consider leaving the prompts blank if you want to do open-ended generation, otherwise ensure prompts are different\n",
      "\n",
      "Aborting..."
     ]
    }
   ],
   "source": [
    "!openai tools fine_tunes.prepare_data -f output.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "openai.api_key = OPENAI_KEY\n",
    "openai.File.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.File.create(\n",
    "  file=open(\"output.jsonl\"),\n",
    "  purpose=\"fine_tuning_topic_generalist\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(openai.File.list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.Completion.create(\n",
    "  engine=\"babbage\",\n",
    "  prompt=\"Once upon a time\",\n",
    "  max_tokens=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Overview of Colaboratory Features",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('3.8.11')",
   "language": "python",
   "name": "python381164bit3811cb326cb84217401495e5946f27ee54a2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}