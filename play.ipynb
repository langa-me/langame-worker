{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langame_client import LangameClient\n",
    "from pprint import pprint\n",
    "from firebase_admin import firestore\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = LangameClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(DatetimeWithNanoseconds(2021, 7, 16, 15, 49, 26, 906587, tzinfo=datetime.timezone.utc),\n <google.cloud.firestore_v1.document.DocumentReference object at 0x7f4c13177610>)\n"
     ]
    }
   ],
   "source": [
    "# TODO: use protobuf\n",
    "p = {}\n",
    "p[\"type\"] = \"TopicGeneralist\"\n",
    "p[\"template\"] = \"\"\"This is a conversation starter that leads to extremely profound conversations between people about \"[TOPIC]\".\n",
    "Starter: What do you think of the theory that animals have emotions?\n",
    "Starter: What is the role of philosophy in human society?\n",
    "Starter: How does one recognize truth and knowledge? What are the ways to acquire it?\n",
    "Starter:\"\"\"\n",
    "t = {\n",
    "    \"createdAt\": firestore.SERVER_TIMESTAMP,\n",
    "    \"engine\": {\n",
    "        \"parameters\": {\n",
    "            \"model\": \"davinci\",\n",
    "            \"temperature\": 0.7,\n",
    "            \"maxTokens\": 150,\n",
    "            \"topP\": 1,\n",
    "            \"frequencyPenalty\": 0.1,\n",
    "            \"presencePenalty\": 0.1,\n",
    "            \"stop\": [\"\\\\n\", \"Starter:\"],\n",
    "        }\n",
    "    }\n",
    "}\n",
    "p_col = langame_client._firestore_client.collection(\"prompts\")\n",
    "new_prompt_ref = p_col.add(p)\n",
    "pprint(p_col.document(new_prompt_ref[1].id).collection(\"tags\").add(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(DatetimeWithNanoseconds(2021, 7, 30, 14, 29, 29, 759625, tzinfo=datetime.timezone.utc),\n <google.cloud.firestore_v1.document.DocumentReference object at 0x7f7db4610b80>)\n"
     ]
    }
   ],
   "source": [
    "p = {}\n",
    "p[\"type\"] = \"TopicGeneralistFineTuned\"\n",
    "p[\"template\"] = \"[TOPIC]. ->\"\n",
    "t = {\n",
    "    \"createdAt\": firestore.SERVER_TIMESTAMP,\n",
    "    \"engine\": {\n",
    "        \"parameters\": {\n",
    "            \"model\": get_model_by_dataset_name(\"generate-generalist-0.0.1.jsonl\")[\"fine_tuned_model\"],\n",
    "            \"temperature\": 0.7,\n",
    "            \"maxTokens\": 150,\n",
    "            \"topP\": 1,\n",
    "            \"frequencyPenalty\": 0.1,\n",
    "            \"presencePenalty\": 0.1,\n",
    "            \"stop\": [\"\\\\n\", \"Starter:\"],\n",
    "        }\n",
    "    }\n",
    "}\n",
    "p_col = langame_client._firestore_client.collection(\"prompts\")\n",
    "new_prompt_ref = p_col.add(p)\n",
    "pprint(p_col.document(new_prompt_ref[1].id).collection(\"tags\").add(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "calling openai with {'id': '544wPT15TsrSuNtpAyUQ', 'prompt': 'This is a conversation starter that leads to extremely profound conversations between people about \"knowledge\".\\nStarter: What do you think of the theory that animals have emotions?\\nStarter: What is the role of philosophy in human society?\\nStarter: How does one recognize truth and knowledge? What are the ways to acquire it?\\nStarter:', 'parameters': {'topP': 1, 'temperature': 0.7, 'frequencyPenalty': 0.1, 'presencePenalty': 0.1, 'model': 'davinci', 'maxTokens': 150, 'stop': ['\\\\n', 'Starter:']}}\n",
      "calling openai with {'id': '544wPT15TsrSuNtpAyUQ', 'prompt': 'This is a conversation starter that leads to extremely profound conversations between people about \"knowledge\".\\nStarter: What do you think of the theory that animals have emotions?\\nStarter: What is the role of philosophy in human society?\\nStarter: How does one recognize truth and knowledge? What are the ways to acquire it?\\nStarter:', 'parameters': {'temperature': 0.7, 'presencePenalty': 0.1, 'frequencyPenalty': 0.1, 'topP': 1, 'maxTokens': 150, 'stop': ['\\\\n', 'Starter:'], 'model': 'davinci'}}\n",
      "calling openai with {'id': '544wPT15TsrSuNtpAyUQ', 'prompt': 'This is a conversation starter that leads to extremely profound conversations between people about \"knowledge\".\\nStarter: What do you think of the theory that animals have emotions?\\nStarter: What is the role of philosophy in human society?\\nStarter: How does one recognize truth and knowledge? What are the ways to acquire it?\\nStarter:', 'parameters': {'maxTokens': 150, 'model': 'davinci', 'temperature': 0.7, 'topP': 1, 'stop': ['\\\\n', 'Starter:'], 'presencePenalty': 0.1, 'frequencyPenalty': 0.1}}\n",
      "calling openai with {'id': '544wPT15TsrSuNtpAyUQ', 'prompt': 'This is a conversation starter that leads to extremely profound conversations between people about \"knowledge\".\\nStarter: What do you think of the theory that animals have emotions?\\nStarter: What is the role of philosophy in human society?\\nStarter: How does one recognize truth and knowledge? What are the ways to acquire it?\\nStarter:', 'parameters': {'temperature': 0.7, 'presencePenalty': 0.1, 'frequencyPenalty': 0.1, 'topP': 1, 'maxTokens': 150, 'stop': ['\\\\n', 'Starter:'], 'model': 'davinci'}}\n",
      "calling openai with {'id': '544wPT15TsrSuNtpAyUQ', 'prompt': 'This is a conversation starter that leads to extremely profound conversations between people about \"knowledge\".\\nStarter: What do you think of the theory that animals have emotions?\\nStarter: What is the role of philosophy in human society?\\nStarter: How does one recognize truth and knowledge? What are the ways to acquire it?\\nStarter:', 'parameters': {'frequencyPenalty': 0.1, 'maxTokens': 150, 'topP': 1, 'presencePenalty': 0.1, 'stop': ['\\\\n', 'Starter:'], 'model': 'davinci', 'temperature': 0.7}}\n",
      "calling openai with {'id': '544wPT15TsrSuNtpAyUQ', 'prompt': 'This is a conversation starter that leads to extremely profound conversations between people about \"knowledge\".\\nStarter: What do you think of the theory that animals have emotions?\\nStarter: What is the role of philosophy in human society?\\nStarter: How does one recognize truth and knowledge? What are the ways to acquire it?\\nStarter:', 'parameters': {'temperature': 0.7, 'model': 'davinci', 'stop': ['\\\\n', 'Starter:'], 'presencePenalty': 0.1, 'topP': 1, 'maxTokens': 150, 'frequencyPenalty': 0.1}}\n",
      "calling openai with {'id': '544wPT15TsrSuNtpAyUQ', 'prompt': 'This is a conversation starter that leads to extremely profound conversations between people about \"knowledge\".\\nStarter: What do you think of the theory that animals have emotions?\\nStarter: What is the role of philosophy in human society?\\nStarter: How does one recognize truth and knowledge? What are the ways to acquire it?\\nStarter:', 'parameters': {'presencePenalty': 0.1, 'frequencyPenalty': 0.1, 'maxTokens': 150, 'temperature': 0.7, 'stop': ['\\\\n', 'Starter:'], 'model': 'davinci', 'topP': 1}}\n",
      "calling openai with {'id': '544wPT15TsrSuNtpAyUQ', 'prompt': 'This is a conversation starter that leads to extremely profound conversations between people about \"knowledge\".\\nStarter: What do you think of the theory that animals have emotions?\\nStarter: What is the role of philosophy in human society?\\nStarter: How does one recognize truth and knowledge? What are the ways to acquire it?\\nStarter:', 'parameters': {'topP': 1, 'frequencyPenalty': 0.1, 'presencePenalty': 0.1, 'model': 'davinci', 'stop': ['\\\\n', 'Starter:'], 'maxTokens': 150, 'temperature': 0.7}}\n",
      "calling openai with {'id': '544wPT15TsrSuNtpAyUQ', 'prompt': 'This is a conversation starter that leads to extremely profound conversations between people about \"knowledge\".\\nStarter: What do you think of the theory that animals have emotions?\\nStarter: What is the role of philosophy in human society?\\nStarter: How does one recognize truth and knowledge? What are the ways to acquire it?\\nStarter:', 'parameters': {'model': 'davinci', 'temperature': 0.7, 'topP': 1, 'maxTokens': 150, 'presencePenalty': 0.1, 'frequencyPenalty': 0.1, 'stop': ['\\\\n', 'Starter:']}}\n",
      "calling openai with {'id': '544wPT15TsrSuNtpAyUQ', 'prompt': 'This is a conversation starter that leads to extremely profound conversations between people about \"knowledge\".\\nStarter: What do you think of the theory that animals have emotions?\\nStarter: What is the role of philosophy in human society?\\nStarter: How does one recognize truth and knowledge? What are the ways to acquire it?\\nStarter:', 'parameters': {'presencePenalty': 0.1, 'frequencyPenalty': 0.1, 'maxTokens': 150, 'stop': ['\\\\n', 'Starter:'], 'temperature': 0.7, 'model': 'davinci', 'topP': 1}}\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    langame_client.prompt_to_meme(\"knowledge\", model=\"TopicGeneralist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(DatetimeWithNanoseconds(2021, 7, 16, 15, 34, 18, 122873, tzinfo=datetime.timezone.utc),\n <google.cloud.firestore_v1.document.DocumentReference object at 0x7f4c131a0fd0>)\n"
     ]
    }
   ],
   "source": [
    "# TODO: use protobuf\n",
    "p = {}\n",
    "p[\"type\"] = \"IceBreakerGeneralist\"\n",
    "p[\"template\"] = \"\"\"This is conversation starters that leads to extremely personal discussions between people.\n",
    "Starter: What is an interesting fact that few people know about you?\n",
    "Starter: What is something that most people take for granted, but has a deeper meaning to you?\n",
    "Starter:\"\"\"\n",
    "t = {\n",
    "    \"createdAt\": firestore.SERVER_TIMESTAMP,\n",
    "    \"engine\": {\n",
    "        \"parameters\": {\n",
    "            \"model\": \"davinci\",\n",
    "            \"temperature\": 0.7,\n",
    "            \"maxTokens\": 150,\n",
    "            \"topP\": 1,\n",
    "            \"frequencyPenalty\": 0.1,\n",
    "            \"presencePenalty\": 0.1,\n",
    "            \"stop\": [\"\\\\n\", \"Starter:\"],\n",
    "        }\n",
    "    }\n",
    "}\n",
    "p_col = langame_client._firestore_client.collection(\"prompts\")\n",
    "new_prompt_ref = p_col.add(p)\n",
    "pprint(p_col.document(new_prompt_ref[1].id).collection(\"tags\").add(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "calling openai with {'id': 'oCccJ82pVND4znQx3zM5', 'prompt': 'This is conversation starters that leads to extremely personal discussions between people.\\nStarter: What is an interesting fact that few people know about you?\\nStarter: What is something that most people take for granted, but has a deeper meaning to you?\\nStarter:', 'parameters': {'temperature': 0.7, 'maxTokens': 150, 'frequencyPenalty': 0.1, 'model': 'davinci', 'presencePenalty': 0.1, 'stop': ['\\\\n', 'Starter:'], 'topP': 1}}\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(DatetimeWithNanoseconds(2021, 7, 16, 15, 35, 59, 312111, tzinfo=datetime.timezone.utc),\n",
       " <google.cloud.firestore_v1.document.DocumentReference at 0x7f4c131a0dc0>)"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "langame_client.prompt_to_meme_ice_breaker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = [t.id for t in langame_client._firestore_client.collection(\"topics\").list_documents()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MsVDZJgZRowLLY1wtWuN\nsOoNX5T6EgwzBabWY0Ee\n440\n"
     ]
    }
   ],
   "source": [
    "\n",
    "completions = []\n",
    "for t in langame_client._firestore_client.collection(u\"memes\")\\\n",
    "    .stream():\n",
    "    completions.append({\"topics\": t.get(\"topics\"), \"meme\": t.get(\"content\")})\n",
    "pprint(len(completions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "440"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "dataset = []\n",
    "for e in completions:\n",
    "    ts = \", \".join(e[\"topics\"])\n",
    "    d = {\"prompt\": f\"Topics:\\n{ts}\\nQuestion:\", \"completion\": f\" {e['meme']}\\n###\\n\"}\n",
    "    dataset.append(d)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "file_name = 'data/generate-generalist-0.0.2.jsonl'\n",
    "with open(file_name, 'w') as outfile:\n",
    "    for entry in dataset:\n",
    "        json.dump(entry, outfile)\n",
    "        outfile.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Analyzing...\n",
      "\n",
      "- Your file contains 440 prompt-completion pairs\n",
      "- There are 2 duplicated prompt-completion pairs. These are rows: [360, 377]\n",
      "- All prompts end with suffix `\\nQuestion:`\n",
      "- All prompts start with prefix `Topics:\n",
      "`\n",
      "- All completions end with suffix `\\n###\\n`\n",
      "\n",
      "Based on the analysis we will perform the following actions:\n",
      "- [Recommended] Remove 2 duplicate rows [Y/n]: ^C\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!openai tools fine_tunes.prepare_data -f $file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Upload progress: 100%|██████████| 77.9k/77.9k [00:00<00:00, 194kit/s]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "RateLimitError",
     "evalue": "You have reached the maximum number of fine-tunes allowed for your organization for this month (10). Please contact finetuning@openai.com and tell us about your use-case if you would like this limit increased.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/hq/swhzs3js29z7mb5b7ycnjcnm0000gn/T/ipykernel_15655/4121865364.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mpurpose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"fine-tune\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n\u001b[0;32m----> 6\u001b[0;31m f_t = openai.FineTune.create(\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mtraining_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"curie\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/langame-worker/.venv/lib/python3.9/site-packages/openai/api_resources/abstract/createable_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, api_key, api_base, idempotency_key, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopulate_headers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midempotency_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequestor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         return util.convert_to_openai_object(\n",
      "\u001b[0;32m~/Documents/langame-worker/.venv/lib/python3.9/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, stream)\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         )\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpret_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_api_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/langame-worker/.venv/lib/python3.9/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36minterpret_response\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    346\u001b[0m             )\n\u001b[1;32m    347\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpret_response_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minterpret_response_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/langame-worker/.venv/lib/python3.9/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36minterpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0mstream_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"error\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstream_error\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mrcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m             raise self.handle_error_response(\n\u001b[0m\u001b[1;32m    368\u001b[0m                 \u001b[0mrbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m             )\n",
      "\u001b[0;31mRateLimitError\u001b[0m: You have reached the maximum number of fine-tunes allowed for your organization for this month (10). Please contact finetuning@openai.com and tell us about your use-case if you would like this limit increased."
     ]
    }
   ],
   "source": [
    "import openai\n",
    "f = openai.File.create(\n",
    "  file=open(file_name),\n",
    "  purpose=\"fine-tune\"\n",
    ")\n",
    "f_t = openai.FineTune.create(\n",
    "    training_file=f[\"id\"],\n",
    "    model=\"curie\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<FineTune fine-tune id=ft-5DIo5s9BIk7ZLwB8biEVnzHB at 0x7f7db4395e50> JSON: {\n",
       "  \"created_at\": 1627653967,\n",
       "  \"fine_tuned_model\": null,\n",
       "  \"hyperparams\": {\n",
       "    \"batch_size\": 4,\n",
       "    \"learning_rate_multiplier\": 0.1,\n",
       "    \"n_epochs\": 4,\n",
       "    \"prompt_loss_weight\": 0.1,\n",
       "    \"use_packing\": null\n",
       "  },\n",
       "  \"id\": \"ft-5DIo5s9BIk7ZLwB8biEVnzHB\",\n",
       "  \"model\": \"curie\",\n",
       "  \"object\": \"fine-tune\",\n",
       "  \"organization_id\": \"org-6iVquBDkjuvNsgZOGPJsaRAs\",\n",
       "  \"result_files\": [],\n",
       "  \"status\": \"pending\",\n",
       "  \"training_files\": [\n",
       "    {\n",
       "      \"bytes\": 35542,\n",
       "      \"created_at\": 1627653912,\n",
       "      \"filename\": \"generate-generalist-0.0.1.jsonl\",\n",
       "      \"id\": \"file-wgDEM5MCzKoqGfW8N5FCEL6U\",\n",
       "      \"object\": \"file\",\n",
       "      \"purpose\": \"fine-tune\",\n",
       "      \"status\": \"processed\",\n",
       "      \"status_details\": null\n",
       "    }\n",
       "  ],\n",
       "  \"updated_at\": 1627653972,\n",
       "  \"user_id\": \"user-fs8ZlgenluyrbB3JQwgRc7O8\",\n",
       "  \"validation_files\": []\n",
       "}"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "model = get_model_by_dataset_name(\"generate-generalist-0.0.2.jsonl\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-3O9em9S5iLE0b0IXIJSxFb004GtuE at 0x7f560072c770> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \" Are there any changes in human evolution that we have not experienced yet in our lifetime, locations at which universal humanism is furthest from what we are used to, and perhaps will be even further away from some day in the future\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1626886004,\n",
       "  \"id\": \"cmpl-3O9em9S5iLE0b0IXIJSxFb004GtuE\",\n",
       "  \"model\": \"curie:ft-beaumont-2021-07-21-16-19-54\",\n",
       "  \"object\": \"text_completion\"\n",
       "}"
      ]
     },
     "metadata": {},
     "execution_count": 76
    }
   ],
   "source": [
    "openai.Completion.create(\n",
    "  model=model[\"fine_tuned_model\"],\n",
    "  prompt=\"Transhumanism. ->\",\n",
    "  max_tokens=100,\n",
    "  stop=[\"\\n\"]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Overview of Colaboratory Features",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('.venv': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "interpreter": {
   "hash": "2ca8946d339ea3bbaa73adc6693d06c322e424e77befb9c6b521a96205a94f7d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}