{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langame_client import LangameClient\n",
    "from pprint import pprint\n",
    "from firebase_admin import firestore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "The default Firebase app already exists. This means you called initialize_app() more than once without providing an app name as the second argument. In most cases you only need to call initialize_app() once. But if you do want to initialize multiple apps, pass a second argument to initialize_app() to give each app a unique name.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3561/541360083.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlangame_client\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLangameClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/workspace/langame-worker/langame_client.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     35\u001b[0m         cred = credentials.Certificate(\n\u001b[1;32m     36\u001b[0m             f'{os.getcwd()}/{conf[\"google\"][\"service_account\"]}')\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mfirebase_admin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_app\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_firestore_client\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mBaseClient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfirestore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         self._memes_ref: BaseCollectionReference = self._firestore_client.collection(\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.11/lib/python3.8/site-packages/firebase_admin/__init__.py\u001b[0m in \u001b[0;36minitialize_app\u001b[0;34m(credential, options, name)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DEFAULT_APP_NAME\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         raise ValueError((\n\u001b[0m\u001b[1;32m     72\u001b[0m             \u001b[0;34m'The default Firebase app already exists. This means you called '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0;34m'initialize_app() more than once without providing an app name as '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The default Firebase app already exists. This means you called initialize_app() more than once without providing an app name as the second argument. In most cases you only need to call initialize_app() once. But if you do want to initialize multiple apps, pass a second argument to initialize_app() to give each app a unique name."
     ]
    }
   ],
   "source": [
    "langame_client = LangameClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(DatetimeWithNanoseconds(2021, 7, 16, 15, 49, 26, 906587, tzinfo=datetime.timezone.utc),\n <google.cloud.firestore_v1.document.DocumentReference object at 0x7f4c13177610>)\n"
     ]
    }
   ],
   "source": [
    "# TODO: use protobuf\n",
    "p = {}\n",
    "p[\"type\"] = \"TopicGeneralist\"\n",
    "p[\"template\"] = \"\"\"This is a conversation starter that leads to extremely profound conversations between people about \"[TOPIC]\".\n",
    "Starter: What do you think of the theory that animals have emotions?\n",
    "Starter: What is the role of philosophy in human society?\n",
    "Starter: How does one recognize truth and knowledge? What are the ways to acquire it?\n",
    "Starter:\"\"\"\n",
    "t = {\n",
    "    \"createdAt\": firestore.SERVER_TIMESTAMP,\n",
    "    \"engine\": {\n",
    "        \"parameters\": {\n",
    "            \"model\": \"davinci\",\n",
    "            \"temperature\": 0.7,\n",
    "            \"maxTokens\": 150,\n",
    "            \"topP\": 1,\n",
    "            \"frequencyPenalty\": 0.1,\n",
    "            \"presencePenalty\": 0.1,\n",
    "            \"stop\": [\"\\\\n\", \"Starter:\"],\n",
    "        }\n",
    "    }\n",
    "}\n",
    "p_col = langame_client._firestore_client.collection(\"prompts\")\n",
    "new_prompt_ref = p_col.add(p)\n",
    "pprint(p_col.document(new_prompt_ref[1].id).collection(\"tags\").add(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "calling openai with {'id': '4IpLQkq4VwnV4M3HheIg', 'prompt': 'It is a question that leads to extremely profound conversations between people about \"transhumanism\":\\n1.', 'parameters': {'temperature': 0.7, 'topP': 1, 'stop': ['\\\\n', '2.'], 'presencePenalty': 0.1, 'model': 'davinci', 'frequencyPenalty': 0.1, 'maxTokens': 150}}\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(DatetimeWithNanoseconds(2021, 7, 16, 15, 50, 4, 77231, tzinfo=datetime.timezone.utc),\n",
       " <google.cloud.firestore_v1.document.DocumentReference at 0x7f4c88307730>)"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "langame_client.prompt_to_meme(topic_with_emoji = \n",
    "    (\"transhumanism\", \"ü§îüß†üí≠üìöüìñüìêüß¨ü§ñü¶æü¶ø\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "calling openai with {'id': '4IpLQkq4VwnV4M3HheIg', 'prompt': 'It is a question that leads to extremely profound conversations between people about \"politic\":\\n1.', 'parameters': {'model': 'davinci', 'topP': 1, 'stop': ['\\\\n', '2.'], 'frequencyPenalty': 0.1, 'presencePenalty': 0.1, 'maxTokens': 150, 'temperature': 0.7}}\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(DatetimeWithNanoseconds(2021, 7, 16, 15, 50, 58, 292063, tzinfo=datetime.timezone.utc),\n",
       " <google.cloud.firestore_v1.document.DocumentReference at 0x7f4c13177250>)"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "langame_client.prompt_to_meme(topic_with_emoji = \n",
    "    (\"politic\", \"ü§îüí≠üìúüèõüë®üë©‚öñüóΩ\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "calling openai with {'id': '4IpLQkq4VwnV4M3HheIg', 'prompt': 'It is a question that leads to extremely profound conversations between people about \"mind\":\\n1.', 'parameters': {'maxTokens': 150, 'temperature': 0.7, 'model': 'davinci', 'stop': ['\\\\n', '2.'], 'frequencyPenalty': 0.1, 'presencePenalty': 0.1, 'topP': 1}}\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(DatetimeWithNanoseconds(2021, 7, 16, 15, 50, 29, 41695, tzinfo=datetime.timezone.utc),\n",
       " <google.cloud.firestore_v1.document.DocumentReference at 0x7f4c13e6d3a0>)"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "langame_client.prompt_to_meme(topic_with_emoji = \n",
    "    (\"mind\", \"ü§îüß†üí≠üìöüìñ\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'content': '\"If money is the root of all evil, what is the root of money?\"',\n",
      " 'createdAt': DatetimeWithNanoseconds(2021, 7, 7, 20, 20, 53, 806000, tzinfo=<UTC>),\n",
      " 'promptId': '4IpLQkq4VwnV4M3HheIg',\n",
      " 'translated': {'de': '\"Wenn Geld die Wurzel allen √úbels ist, was ist dann die '\n",
      "                      'Wurzel des Geldes?\"',\n",
      "                'es': '\"Si el dinero es la ra√≠z de todos los males, ¬øcu√°l es '\n",
      "                      'la ra√≠z del dinero?\"',\n",
      "                'fr': \"¬´ Si l'argent est la racine de tous les maux, quelle \"\n",
      "                      \"est la racine de l'argent ?\"}}\n",
      "{'content': '\"Are we talking about a \"state\" or a \"government\"?\"',\n",
      " 'createdAt': DatetimeWithNanoseconds(2021, 7, 7, 20, 19, 57, 328000, tzinfo=<UTC>),\n",
      " 'promptId': '4IpLQkq4VwnV4M3HheIg',\n",
      " 'translated': {'de': '\"Reden wir von einem \"Staat\" oder einer \"Regierung\"?\"',\n",
      "                'es': '\"¬øEstamos hablando de un\" estado \"o un\" gobierno \"?\"',\n",
      "                'fr': \"¬´ Parlons-nous d'un ¬´ √âtat ¬ª ou d'un ¬´ gouvernement ¬ª \"\n",
      "                      '?'}}\n",
      "{'content': '\"Cynicism vs. idealism\"',\n",
      " 'createdAt': DatetimeWithNanoseconds(2021, 7, 7, 20, 9, 1, 341000, tzinfo=<UTC>),\n",
      " 'promptId': 'elmPKsEuVytQrgS6RWTF',\n",
      " 'translated': {'de': '\"Zynismus vs. Idealismus\"',\n",
      "                'es': '\"Cinismo vs idealismo\"',\n",
      "                'fr': '\"Cynisme contre id√©alisme\"'}}\n",
      "{'content': '\"What\\'s your favorite book?\"\\n'\n",
      "            '\\n'\n",
      "            'Deep conversations about books are often sparked by this '\n",
      "            'question.',\n",
      " 'createdAt': DatetimeWithNanoseconds(2021, 7, 7, 15, 25, 50, 249000, tzinfo=<UTC>),\n",
      " 'promptId': 'uv5MS4pDr3AF5Qgbo1gi',\n",
      " 'translated': {'de': '\"Was ist dein Lieblingsbuch?\"\\n'\n",
      "                      '\\n'\n",
      "                      'Durch diese Frage werden oft tiefe Gespr√§che √ºber '\n",
      "                      'B√ºcher entz√ºndet.',\n",
      "                'es': '\"¬øCu√°l es tu libro favorito?\"\\n'\n",
      "                      '\\n'\n",
      "                      'Esta pregunta a menudo suscita conversaciones profundas '\n",
      "                      'sobre libros.',\n",
      "                'fr': '¬´\\xa0Quel est votre livre pr√©f√©r√©\\xa0?\\xa0¬ª\\n'\n",
      "                      '\\n'\n",
      "                      'Des conversations profondes sur les livres sont souvent '\n",
      "                      'd√©clench√©es par cette question.'}}\n",
      "{'content': \"I'm not sure if you're like me, but I've heard it's hard to start \"\n",
      "            \"a conversation with strangers or people you don't know.\\n\"\n",
      "            \"Well, I'm not sure if this is the best idea in the world, but \"\n",
      "            'what do you think if we try to start a conversation about the '\n",
      "            'weather?',\n",
      " 'createdAt': DatetimeWithNanoseconds(2021, 7, 7, 8, 2, 56, 265000, tzinfo=<UTC>),\n",
      " 'promptId': 'uv5MS4pDr3AF5Qgbo1gi',\n",
      " 'translated': {'de': 'Ich bin mir nicht sicher, ob Sie wie ich sind, aber ich '\n",
      "                      'habe geh√∂rt, dass es schwierig ist, mit Fremden oder '\n",
      "                      'Unbekannten ins Gespr√§ch zu kommen.\\n'\n",
      "                      'Nun, ich bin mir nicht sicher, ob das die beste Idee '\n",
      "                      'der Welt ist, aber was denkst du, wenn wir versuchen, '\n",
      "                      'ein Gespr√§ch √ºber das Wetter zu beginnen?',\n",
      "                'es': 'No estoy seguro de si eres como yo, pero he o√≠do que es '\n",
      "                      'dif√≠cil iniciar una conversaci√≥n con extra√±os o '\n",
      "                      'personas que no conoces.\\n'\n",
      "                      'Bueno, no estoy seguro si esta es la mejor idea del '\n",
      "                      'mundo, pero ¬øqu√© piensas si intentamos iniciar una '\n",
      "                      'conversaci√≥n sobre el clima?',\n",
      "                'fr': \"Je ne sais pas si vous √™tes comme moi, mais j'ai \"\n",
      "                      \"entendu dire qu'il est difficile d'entamer une \"\n",
      "                      'conversation avec des inconnus ou des personnes que '\n",
      "                      'vous ne connaissez pas.\\n'\n",
      "                      \"Eh bien, je ne sais pas si c'est la meilleure id√©e au \"\n",
      "                      \"monde, mais que pensez-vous si nous essayons d'entamer \"\n",
      "                      'une conversation sur la m√©t√©o ?'}}\n",
      "{'content': 'If you could be absolutely certain of something, what would it '\n",
      "            'be?',\n",
      " 'createdAt': DatetimeWithNanoseconds(2021, 6, 15, 10, 3, 36, 206000, tzinfo=<UTC>)}\n",
      "{'content': 'What do you fantasize about?',\n",
      " 'createdAt': DatetimeWithNanoseconds(2021, 6, 15, 10, 3, 36, 206000, tzinfo=<UTC>)}\n",
      "{'content': 'What are your thoughts on religion, God or spirituality?',\n",
      " 'createdAt': DatetimeWithNanoseconds(2021, 6, 15, 10, 3, 34, 120000, tzinfo=<UTC>)}\n",
      "{'content': 'What is the most valuable thought that you have had today?',\n",
      " 'createdAt': DatetimeWithNanoseconds(2021, 6, 15, 10, 3, 34, 120000, tzinfo=<UTC>)}\n",
      "{'content': 'What kind of person are you when you are your true self?',\n",
      " 'createdAt': DatetimeWithNanoseconds(2021, 6, 15, 10, 3, 31, 997000, tzinfo=<UTC>)}\n"
     ]
    }
   ],
   "source": [
    "for t in langame_client._firestore_client.collection_group(u\"tags\")\\\n",
    "    .where(u\"topic.content\", u\"in\", [\"ice breaker\"])\\\n",
    "    .order_by(u\"createdAt\", direction=firestore.Query.DESCENDING)\\\n",
    "    .limit(10)\\\n",
    "    .stream():\n",
    "    pprint(t.reference.parent.parent.get().to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(DatetimeWithNanoseconds(2021, 7, 16, 15, 34, 18, 122873, tzinfo=datetime.timezone.utc),\n <google.cloud.firestore_v1.document.DocumentReference object at 0x7f4c131a0fd0>)\n"
     ]
    }
   ],
   "source": [
    "# TODO: use protobuf\n",
    "p = {}\n",
    "p[\"type\"] = \"IceBreakerGeneralist\"\n",
    "p[\"template\"] = \"\"\"This is conversation starters that leads to extremely personal discussions between people.\n",
    "Starter: What is an interesting fact that few people know about you?\n",
    "Starter: What is something that most people take for granted, but has a deeper meaning to you?\n",
    "Starter:\"\"\"\n",
    "t = {\n",
    "    \"createdAt\": firestore.SERVER_TIMESTAMP,\n",
    "    \"engine\": {\n",
    "        \"parameters\": {\n",
    "            \"model\": \"davinci\",\n",
    "            \"temperature\": 0.7,\n",
    "            \"maxTokens\": 150,\n",
    "            \"topP\": 1,\n",
    "            \"frequencyPenalty\": 0.1,\n",
    "            \"presencePenalty\": 0.1,\n",
    "            \"stop\": [\"\\\\n\", \"Starter:\"],\n",
    "        }\n",
    "    }\n",
    "}\n",
    "p_col = langame_client._firestore_client.collection(\"prompts\")\n",
    "new_prompt_ref = p_col.add(p)\n",
    "pprint(p_col.document(new_prompt_ref[1].id).collection(\"tags\").add(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "calling openai with {'id': 'oCccJ82pVND4znQx3zM5', 'prompt': 'This is conversation starters that leads to extremely personal discussions between people.\\nStarter: What is an interesting fact that few people know about you?\\nStarter: What is something that most people take for granted, but has a deeper meaning to you?\\nStarter:', 'parameters': {'temperature': 0.7, 'maxTokens': 150, 'frequencyPenalty': 0.1, 'model': 'davinci', 'presencePenalty': 0.1, 'stop': ['\\\\n', 'Starter:'], 'topP': 1}}\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(DatetimeWithNanoseconds(2021, 7, 16, 15, 35, 59, 312111, tzinfo=datetime.timezone.utc),\n",
       " <google.cloud.firestore_v1.document.DocumentReference at 0x7f4c131a0dc0>)"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "langame_client.prompt_to_meme_ice_breaker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'template': 'It is a question that leads to extremely profound conversations '\n             'between people about \"[TOPIC]\":\\n'\n             '1.',\n 'type': 'TopicGeneralist'}\n{'template': 'Provide me a conversation starter that brings extremely deeply '\n             'personal conversations between people, thus breaking the ice.\\n'\n             'Starter:',\n 'type': 'IceBreakerGeneralist'}\n{'template': 'This is a question that leads to extremely profound '\n             'conversations between people and allow them to break the ice:\\n'\n             '1.',\n 'type': 'IceBreakerGeneralist'}\n"
     ]
    }
   ],
   "source": [
    "for e in langame_client._firestore_client.collection(\"prompts\")\\\n",
    "        .limit(5)\\\n",
    "        .stream():\n",
    "    pprint(e.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "171\n"
     ]
    }
   ],
   "source": [
    "\n",
    "completions = []\n",
    "topics = [\"philosophy\", \"physic\", \"mathematic\", \"biology\", \"transhumanism\", \"artificial intelligence\", \"book\"]\n",
    "for t in langame_client._firestore_client.collection_group(u\"tags\")\\\n",
    "    .where(u\"topic.content\", u\"in\", topics)\\\n",
    "    .order_by(u\"createdAt\", direction=firestore.Query.DESCENDING)\\\n",
    "    .stream():\n",
    "    completions.append({\"topic\": t.to_dict()[\"topic\"][\"content\"], \"meme\": t.reference.parent.parent.get().to_dict()[\"content\"]})\n",
    "pprint(len(completions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#{\"prompt\": \"<prompt text>\", \"completion\": \"<ideal generated text>\"}\n",
    "def get_prompt(topic):\n",
    "    return f\"\"\"This is a conversation starter that leads to extremely profound conversations between people about \"{topic}\".\n",
    "Starter:\"\"\"\n",
    "\n",
    "dataset = [{\"prompt\": get_prompt(e[\"topic\"]), \"completion\": f\" {e['meme']}\"} for e in completions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('output.jsonl', 'w') as outfile:\n",
    "    for entry in dataset:\n",
    "        json.dump(entry, outfile)\n",
    "        outfile.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Analyzing...\n",
      "\n",
      "- Your file contains 56 prompt-completion pairs. In general, we recommend having at least a few hundred examples. We've found that performance tends to linearly increase for every doubling of the number of examples\n",
      "\n",
      "ERROR in common_suffix validator: All prompts are identical: `This is a conversation starter that leads to extremely profound conversations between people about \"philosophy\".\n",
      "Starter:`\n",
      "Consider leaving the prompts blank if you want to do open-ended generation, otherwise ensure prompts are different\n",
      "\n",
      "Aborting..."
     ]
    }
   ],
   "source": [
    "!openai tools fine_tunes.prepare_data -f output.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<OpenAIObject list at 0x7f46cfe6f770> JSON: {\n",
       "  \"data\": [],\n",
       "  \"object\": \"list\"\n",
       "}"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "import openai\n",
    "openai.File.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Upload progress: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 54.1k/54.1k [00:00<00:00, 5.92Mit/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<File file id=file-xiORWPq4g2IsFNYD7ZVPLVB3 at 0x7f46cfdf75e0> JSON: {\n",
       "  \"bytes\": 53872,\n",
       "  \"created_at\": 1626524028,\n",
       "  \"filename\": \"output.jsonl\",\n",
       "  \"id\": \"file-xiORWPq4g2IsFNYD7ZVPLVB3\",\n",
       "  \"object\": \"file\",\n",
       "  \"purpose\": \"fine-tune\",\n",
       "  \"status\": \"uploaded\",\n",
       "  \"status_details\": null\n",
       "}"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "openai.File.create(\n",
    "  file=open(\"output.jsonl\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<File file id=file-xiORWPq4g2IsFNYD7ZVPLVB3 at 0x7f46cc5692c0> JSON: {\n",
       "   \"bytes\": 53872,\n",
       "   \"created_at\": 1626524028,\n",
       "   \"filename\": \"output.jsonl\",\n",
       "   \"id\": \"file-xiORWPq4g2IsFNYD7ZVPLVB3\",\n",
       "   \"object\": \"file\",\n",
       "   \"purpose\": \"fine-tune\",\n",
       "   \"status\": \"processed\",\n",
       "   \"status_details\": null\n",
       " }]"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "files = openai.File.list()\n",
    "files.get(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<FineTune fine-tune id=ft-oFMt7ZUOQWYPR3MiIjxqd6Ht at 0x7f4709230720> JSON: {\n",
       "  \"created_at\": 1626524337,\n",
       "  \"events\": [\n",
       "    {\n",
       "      \"created_at\": 1626524337,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Created fine-tune: ft-oFMt7ZUOQWYPR3MiIjxqd6Ht\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    }\n",
       "  ],\n",
       "  \"fine_tuned_model\": null,\n",
       "  \"hyperparams\": {\n",
       "    \"batch_size\": 4,\n",
       "    \"learning_rate_multiplier\": 0.1,\n",
       "    \"n_epochs\": 4,\n",
       "    \"prompt_loss_weight\": 0.1,\n",
       "    \"use_packing\": null\n",
       "  },\n",
       "  \"id\": \"ft-oFMt7ZUOQWYPR3MiIjxqd6Ht\",\n",
       "  \"model\": \"curie\",\n",
       "  \"object\": \"fine-tune\",\n",
       "  \"organization_id\": \"org-6iVquBDkjuvNsgZOGPJsaRAs\",\n",
       "  \"result_files\": [],\n",
       "  \"status\": \"pending\",\n",
       "  \"training_files\": [\n",
       "    {\n",
       "      \"bytes\": 53872,\n",
       "      \"created_at\": 1626524028,\n",
       "      \"filename\": \"output.jsonl\",\n",
       "      \"id\": \"file-xiORWPq4g2IsFNYD7ZVPLVB3\",\n",
       "      \"object\": \"file\",\n",
       "      \"purpose\": \"fine-tune\",\n",
       "      \"status\": \"processed\",\n",
       "      \"status_details\": null\n",
       "    }\n",
       "  ],\n",
       "  \"updated_at\": 1626524337,\n",
       "  \"user_id\": \"user-fs8ZlgenluyrbB3JQwgRc7O8\",\n",
       "  \"validation_files\": []\n",
       "}"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "openai.FineTune.create(\n",
    "    training_file=files[\"data\"][0][\"id\"],\n",
    "    model=\"curie\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "model = openai.FineTune.list()[\"data\"][0][\"fine_tuned_model\"]\n",
    "pprint(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.Completion.create(\n",
    "  engine=model,\n",
    "  prompt=\"\"\"Philosophy.\n",
    "Starter:\"\"\",\n",
    "  max_tokens=100\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Overview of Colaboratory Features",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('3.8.11')",
   "language": "python",
   "name": "python381164bit3811986d4323da374559b912b171f498b4fa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}