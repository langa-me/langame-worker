{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langame_client import LangameClient\n",
    "from pprint import pprint\n",
    "from firebase_admin import firestore\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import openai\n",
    "def get_model_by_dataset_name(dataset_name):\n",
    "  return [e for e in openai.FineTune.list()[\"data\"] if e[\"training_files\"][0][\"filename\"] == dataset_name][0]\n",
    "# If fine_tuned_model is null, it means you have to wait OpenAI process the fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "langame_client = LangameClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(DatetimeWithNanoseconds(2021, 7, 16, 15, 49, 26, 906587, tzinfo=datetime.timezone.utc),\n <google.cloud.firestore_v1.document.DocumentReference object at 0x7f4c13177610>)\n"
     ]
    }
   ],
   "source": [
    "# TODO: use protobuf\n",
    "p = {}\n",
    "p[\"type\"] = \"TopicGeneralist\"\n",
    "p[\"template\"] = \"\"\"This is a conversation starter that leads to extremely profound conversations between people about \"[TOPIC]\".\n",
    "Starter: What do you think of the theory that animals have emotions?\n",
    "Starter: What is the role of philosophy in human society?\n",
    "Starter: How does one recognize truth and knowledge? What are the ways to acquire it?\n",
    "Starter:\"\"\"\n",
    "t = {\n",
    "    \"createdAt\": firestore.SERVER_TIMESTAMP,\n",
    "    \"engine\": {\n",
    "        \"parameters\": {\n",
    "            \"model\": \"davinci\",\n",
    "            \"temperature\": 0.7,\n",
    "            \"maxTokens\": 150,\n",
    "            \"topP\": 1,\n",
    "            \"frequencyPenalty\": 0.1,\n",
    "            \"presencePenalty\": 0.1,\n",
    "            \"stop\": [\"\\\\n\", \"Starter:\"],\n",
    "        }\n",
    "    }\n",
    "}\n",
    "p_col = langame_client._firestore_client.collection(\"prompts\")\n",
    "new_prompt_ref = p_col.add(p)\n",
    "pprint(p_col.document(new_prompt_ref[1].id).collection(\"tags\").add(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(DatetimeWithNanoseconds(2021, 7, 30, 14, 29, 29, 759625, tzinfo=datetime.timezone.utc),\n <google.cloud.firestore_v1.document.DocumentReference object at 0x7f7db4610b80>)\n"
     ]
    }
   ],
   "source": [
    "p = {}\n",
    "p[\"type\"] = \"TopicGeneralistFineTuned\"\n",
    "p[\"template\"] = \"[TOPIC]. ->\"\n",
    "t = {\n",
    "    \"createdAt\": firestore.SERVER_TIMESTAMP,\n",
    "    \"engine\": {\n",
    "        \"parameters\": {\n",
    "            \"model\": get_model_by_dataset_name(\"generate-generalist-0.0.1.jsonl\")[\"fine_tuned_model\"],\n",
    "            \"temperature\": 0.7,\n",
    "            \"maxTokens\": 150,\n",
    "            \"topP\": 1,\n",
    "            \"frequencyPenalty\": 0.1,\n",
    "            \"presencePenalty\": 0.1,\n",
    "            \"stop\": [\"\\\\n\", \"Starter:\"],\n",
    "        }\n",
    "    }\n",
    "}\n",
    "p_col = langame_client._firestore_client.collection(\"prompts\")\n",
    "new_prompt_ref = p_col.add(p)\n",
    "pprint(p_col.document(new_prompt_ref[1].id).collection(\"tags\").add(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "calling openai with {'id': '544wPT15TsrSuNtpAyUQ', 'prompt': 'This is a conversation starter that leads to extremely profound conversations between people about \"knowledge\".\\nStarter: What do you think of the theory that animals have emotions?\\nStarter: What is the role of philosophy in human society?\\nStarter: How does one recognize truth and knowledge? What are the ways to acquire it?\\nStarter:', 'parameters': {'topP': 1, 'temperature': 0.7, 'frequencyPenalty': 0.1, 'presencePenalty': 0.1, 'model': 'davinci', 'maxTokens': 150, 'stop': ['\\\\n', 'Starter:']}}\n",
      "calling openai with {'id': '544wPT15TsrSuNtpAyUQ', 'prompt': 'This is a conversation starter that leads to extremely profound conversations between people about \"knowledge\".\\nStarter: What do you think of the theory that animals have emotions?\\nStarter: What is the role of philosophy in human society?\\nStarter: How does one recognize truth and knowledge? What are the ways to acquire it?\\nStarter:', 'parameters': {'temperature': 0.7, 'presencePenalty': 0.1, 'frequencyPenalty': 0.1, 'topP': 1, 'maxTokens': 150, 'stop': ['\\\\n', 'Starter:'], 'model': 'davinci'}}\n",
      "calling openai with {'id': '544wPT15TsrSuNtpAyUQ', 'prompt': 'This is a conversation starter that leads to extremely profound conversations between people about \"knowledge\".\\nStarter: What do you think of the theory that animals have emotions?\\nStarter: What is the role of philosophy in human society?\\nStarter: How does one recognize truth and knowledge? What are the ways to acquire it?\\nStarter:', 'parameters': {'maxTokens': 150, 'model': 'davinci', 'temperature': 0.7, 'topP': 1, 'stop': ['\\\\n', 'Starter:'], 'presencePenalty': 0.1, 'frequencyPenalty': 0.1}}\n",
      "calling openai with {'id': '544wPT15TsrSuNtpAyUQ', 'prompt': 'This is a conversation starter that leads to extremely profound conversations between people about \"knowledge\".\\nStarter: What do you think of the theory that animals have emotions?\\nStarter: What is the role of philosophy in human society?\\nStarter: How does one recognize truth and knowledge? What are the ways to acquire it?\\nStarter:', 'parameters': {'temperature': 0.7, 'presencePenalty': 0.1, 'frequencyPenalty': 0.1, 'topP': 1, 'maxTokens': 150, 'stop': ['\\\\n', 'Starter:'], 'model': 'davinci'}}\n",
      "calling openai with {'id': '544wPT15TsrSuNtpAyUQ', 'prompt': 'This is a conversation starter that leads to extremely profound conversations between people about \"knowledge\".\\nStarter: What do you think of the theory that animals have emotions?\\nStarter: What is the role of philosophy in human society?\\nStarter: How does one recognize truth and knowledge? What are the ways to acquire it?\\nStarter:', 'parameters': {'frequencyPenalty': 0.1, 'maxTokens': 150, 'topP': 1, 'presencePenalty': 0.1, 'stop': ['\\\\n', 'Starter:'], 'model': 'davinci', 'temperature': 0.7}}\n",
      "calling openai with {'id': '544wPT15TsrSuNtpAyUQ', 'prompt': 'This is a conversation starter that leads to extremely profound conversations between people about \"knowledge\".\\nStarter: What do you think of the theory that animals have emotions?\\nStarter: What is the role of philosophy in human society?\\nStarter: How does one recognize truth and knowledge? What are the ways to acquire it?\\nStarter:', 'parameters': {'temperature': 0.7, 'model': 'davinci', 'stop': ['\\\\n', 'Starter:'], 'presencePenalty': 0.1, 'topP': 1, 'maxTokens': 150, 'frequencyPenalty': 0.1}}\n",
      "calling openai with {'id': '544wPT15TsrSuNtpAyUQ', 'prompt': 'This is a conversation starter that leads to extremely profound conversations between people about \"knowledge\".\\nStarter: What do you think of the theory that animals have emotions?\\nStarter: What is the role of philosophy in human society?\\nStarter: How does one recognize truth and knowledge? What are the ways to acquire it?\\nStarter:', 'parameters': {'presencePenalty': 0.1, 'frequencyPenalty': 0.1, 'maxTokens': 150, 'temperature': 0.7, 'stop': ['\\\\n', 'Starter:'], 'model': 'davinci', 'topP': 1}}\n",
      "calling openai with {'id': '544wPT15TsrSuNtpAyUQ', 'prompt': 'This is a conversation starter that leads to extremely profound conversations between people about \"knowledge\".\\nStarter: What do you think of the theory that animals have emotions?\\nStarter: What is the role of philosophy in human society?\\nStarter: How does one recognize truth and knowledge? What are the ways to acquire it?\\nStarter:', 'parameters': {'topP': 1, 'frequencyPenalty': 0.1, 'presencePenalty': 0.1, 'model': 'davinci', 'stop': ['\\\\n', 'Starter:'], 'maxTokens': 150, 'temperature': 0.7}}\n",
      "calling openai with {'id': '544wPT15TsrSuNtpAyUQ', 'prompt': 'This is a conversation starter that leads to extremely profound conversations between people about \"knowledge\".\\nStarter: What do you think of the theory that animals have emotions?\\nStarter: What is the role of philosophy in human society?\\nStarter: How does one recognize truth and knowledge? What are the ways to acquire it?\\nStarter:', 'parameters': {'model': 'davinci', 'temperature': 0.7, 'topP': 1, 'maxTokens': 150, 'presencePenalty': 0.1, 'frequencyPenalty': 0.1, 'stop': ['\\\\n', 'Starter:']}}\n",
      "calling openai with {'id': '544wPT15TsrSuNtpAyUQ', 'prompt': 'This is a conversation starter that leads to extremely profound conversations between people about \"knowledge\".\\nStarter: What do you think of the theory that animals have emotions?\\nStarter: What is the role of philosophy in human society?\\nStarter: How does one recognize truth and knowledge? What are the ways to acquire it?\\nStarter:', 'parameters': {'presencePenalty': 0.1, 'frequencyPenalty': 0.1, 'maxTokens': 150, 'stop': ['\\\\n', 'Starter:'], 'temperature': 0.7, 'model': 'davinci', 'topP': 1}}\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    langame_client.prompt_to_meme(\"knowledge\", model=\"TopicGeneralist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(DatetimeWithNanoseconds(2021, 7, 16, 15, 34, 18, 122873, tzinfo=datetime.timezone.utc),\n <google.cloud.firestore_v1.document.DocumentReference object at 0x7f4c131a0fd0>)\n"
     ]
    }
   ],
   "source": [
    "# TODO: use protobuf\n",
    "p = {}\n",
    "p[\"type\"] = \"IceBreakerGeneralist\"\n",
    "p[\"template\"] = \"\"\"This is conversation starters that leads to extremely personal discussions between people.\n",
    "Starter: What is an interesting fact that few people know about you?\n",
    "Starter: What is something that most people take for granted, but has a deeper meaning to you?\n",
    "Starter:\"\"\"\n",
    "t = {\n",
    "    \"createdAt\": firestore.SERVER_TIMESTAMP,\n",
    "    \"engine\": {\n",
    "        \"parameters\": {\n",
    "            \"model\": \"davinci\",\n",
    "            \"temperature\": 0.7,\n",
    "            \"maxTokens\": 150,\n",
    "            \"topP\": 1,\n",
    "            \"frequencyPenalty\": 0.1,\n",
    "            \"presencePenalty\": 0.1,\n",
    "            \"stop\": [\"\\\\n\", \"Starter:\"],\n",
    "        }\n",
    "    }\n",
    "}\n",
    "p_col = langame_client._firestore_client.collection(\"prompts\")\n",
    "new_prompt_ref = p_col.add(p)\n",
    "pprint(p_col.document(new_prompt_ref[1].id).collection(\"tags\").add(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "calling openai with {'id': 'oCccJ82pVND4znQx3zM5', 'prompt': 'This is conversation starters that leads to extremely personal discussions between people.\\nStarter: What is an interesting fact that few people know about you?\\nStarter: What is something that most people take for granted, but has a deeper meaning to you?\\nStarter:', 'parameters': {'temperature': 0.7, 'maxTokens': 150, 'frequencyPenalty': 0.1, 'model': 'davinci', 'presencePenalty': 0.1, 'stop': ['\\\\n', 'Starter:'], 'topP': 1}}\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(DatetimeWithNanoseconds(2021, 7, 16, 15, 35, 59, 312111, tzinfo=datetime.timezone.utc),\n",
       " <google.cloud.firestore_v1.document.DocumentReference at 0x7f4c131a0dc0>)"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "langame_client.prompt_to_meme_ice_breaker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "174\n"
     ]
    }
   ],
   "source": [
    "\n",
    "completions = []\n",
    "topics = [\"philosophy\", \"physic\", \"mathematic\", \"biology\", \"transhumanism\", \"artificial intelligence\", \"book\"]\n",
    "for t in langame_client._firestore_client.collection_group(u\"tags\")\\\n",
    "    .where(u\"topic.content\", u\"in\", topics)\\\n",
    "    .order_by(u\"createdAt\", direction=firestore.Query.DESCENDING)\\\n",
    "    .stream():\n",
    "    completions.append({\"topic\": t.to_dict()[\"topic\"][\"content\"], \"meme\": t.reference.parent.parent.get().to_dict()[\"content\"]})\n",
    "pprint(len(completions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [{\"prompt\": f\"{e['topic']} ->\", \"completion\": f\" {e['meme']}\\n\"} for e in completions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "file_name = 'generate-generalist-0.0.1.jsonl'\n",
    "with open(file_name, 'w') as outfile:\n",
    "    for entry in dataset:\n",
    "        json.dump(entry, outfile)\n",
    "        outfile.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Analyzing...\n",
      "\n",
      "- Your file contains 174 prompt-completion pairs\n",
      "- There are 2 duplicated prompt-completion pairs. These are rows: [12, 21]\n",
      "- All prompts end with suffix ` ->`\n",
      "- All completions end with suffix `\\n`\n",
      "  WARNING: Some of your completions contain the suffix `\n",
      "` more than once. We suggest that you review your completions and add a unique ending\n",
      "\n",
      "Based on the analysis we will perform the following actions:\n",
      "- [Recommended] Remove 2 duplicate rows [Y/n]: ^C\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!openai tools fine_tunes.prepare_data -f $file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "Upload progress:   0%|          | 0.00/35.8k [00:00<?, ?it/s]\u001b[A\n",
      "Upload progress:  23%|██▎       | 8.19k/35.8k [00:00<00:00, 32.5kit/s]\u001b[A\n",
      "Upload progress:  46%|████▌     | 16.4k/35.8k [00:00<00:00, 64.5kit/s]\u001b[A\n",
      "Upload progress:  69%|██████▊   | 24.6k/35.8k [00:00<00:00, 96.2kit/s]\u001b[A\n",
      "Upload progress: 100%|██████████| 35.8k/35.8k [00:00<00:00, 139kit/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<File file id=file-wgDEM5MCzKoqGfW8N5FCEL6U at 0x7f7db448c630> JSON: {\n",
       "  \"bytes\": 35542,\n",
       "  \"created_at\": 1627653912,\n",
       "  \"filename\": \"generate-generalist-0.0.1.jsonl\",\n",
       "  \"id\": \"file-wgDEM5MCzKoqGfW8N5FCEL6U\",\n",
       "  \"object\": \"file\",\n",
       "  \"purpose\": \"fine-tune\",\n",
       "  \"status\": \"uploaded\",\n",
       "  \"status_details\": null\n",
       "}"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "import openai\n",
    "f = openai.File.create(\n",
    "  file=open(file_name),\n",
    "  purpose=\"fine-tune\"\n",
    ")\n",
    "f_t = openai.FineTune.create(\n",
    "    training_file=f[\"id\"],\n",
    "    model=\"curie\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<FineTune fine-tune id=ft-5DIo5s9BIk7ZLwB8biEVnzHB at 0x7f7db4395e50> JSON: {\n",
       "  \"created_at\": 1627653967,\n",
       "  \"fine_tuned_model\": null,\n",
       "  \"hyperparams\": {\n",
       "    \"batch_size\": 4,\n",
       "    \"learning_rate_multiplier\": 0.1,\n",
       "    \"n_epochs\": 4,\n",
       "    \"prompt_loss_weight\": 0.1,\n",
       "    \"use_packing\": null\n",
       "  },\n",
       "  \"id\": \"ft-5DIo5s9BIk7ZLwB8biEVnzHB\",\n",
       "  \"model\": \"curie\",\n",
       "  \"object\": \"fine-tune\",\n",
       "  \"organization_id\": \"org-6iVquBDkjuvNsgZOGPJsaRAs\",\n",
       "  \"result_files\": [],\n",
       "  \"status\": \"pending\",\n",
       "  \"training_files\": [\n",
       "    {\n",
       "      \"bytes\": 35542,\n",
       "      \"created_at\": 1627653912,\n",
       "      \"filename\": \"generate-generalist-0.0.1.jsonl\",\n",
       "      \"id\": \"file-wgDEM5MCzKoqGfW8N5FCEL6U\",\n",
       "      \"object\": \"file\",\n",
       "      \"purpose\": \"fine-tune\",\n",
       "      \"status\": \"processed\",\n",
       "      \"status_details\": null\n",
       "    }\n",
       "  ],\n",
       "  \"updated_at\": 1627653972,\n",
       "  \"user_id\": \"user-fs8ZlgenluyrbB3JQwgRc7O8\",\n",
       "  \"validation_files\": []\n",
       "}"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "model = get_model_by_dataset_name(\"generate-generalist-0.0.1.jsonl\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-3O9em9S5iLE0b0IXIJSxFb004GtuE at 0x7f560072c770> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \" Are there any changes in human evolution that we have not experienced yet in our lifetime, locations at which universal humanism is furthest from what we are used to, and perhaps will be even further away from some day in the future\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1626886004,\n",
       "  \"id\": \"cmpl-3O9em9S5iLE0b0IXIJSxFb004GtuE\",\n",
       "  \"model\": \"curie:ft-beaumont-2021-07-21-16-19-54\",\n",
       "  \"object\": \"text_completion\"\n",
       "}"
      ]
     },
     "metadata": {},
     "execution_count": 76
    }
   ],
   "source": [
    "openai.Completion.create(\n",
    "  model=model[\"fine_tuned_model\"],\n",
    "  prompt=\"Transhumanism. ->\",\n",
    "  max_tokens=100,\n",
    "  stop=[\"\\n\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below = fine tunes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://conversationstartersworld.com/philosophical-questions/\"\n",
    "page = requests.get(URL)\n",
    "\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "philosophical_questions = [e.text for e in soup.find(id=\"genesis-content\").find(\"article\").find(\"div\").find_all(\"p\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "memes = []\n",
    "for e in langame_client._firestore_client.collection(\"memes\").stream():\n",
    "    memes.append(e.get(\"content\"))\n",
    "memes = memes + [\" \".join(e.split(\" \")[1:]) for e in philosophical_questions[3:-5]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://conversationstartersworld.com/deep-conversation-topics/\"\n",
    "page = requests.get(URL)\n",
    "\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "deep = [e.text for e in soup.find(id=\"genesis-content\").find(\"article\").find(\"div\").find_all(\"p\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "memes += [\" \".join(e.split(\" \")[1:]) for e in deep[3:-5]]\n",
    "\n",
    "with open('memes.json', 'w') as outfile:\n",
    "    json.dump({\"memes\": memes}, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "URL = \"https://conversationstartersworld.com/hypothetical-questions/\"\n",
    "page = requests.get(URL)\n",
    "\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "hypothetical = [e.text for e in soup.find(id=\"genesis-content\").find(\"article\").find(\"div\").find_all(\"p\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "memes += [\" \".join(e.split(\" \")[1:]) for e in hypothetical[3:-5]]\n",
    "\n",
    "with open('memes.json', 'w') as outfile:\n",
    "    json.dump({\"memes\": memes}, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://conversationstartersworld.com/open-ended-questions/\"\n",
    "page = requests.get(URL)\n",
    "\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "open_ended = [e.text for e in soup.find(id=\"genesis-content\").find(\"article\").find(\"div\").find_all(\"p\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "memes += [\" \".join(e.split(\" \")[1:]) for e in open_ended[3:-5]]\n",
    "\n",
    "with open('memes.json', 'w') as outfile:\n",
    "    json.dump({\"memes\": memes}, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "URL = \"https://conversationstartersworld.com/closed-ended-questions-3/\"\n",
    "page = requests.get(URL)\n",
    "\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "closed_ended = [e.text for e in soup.find(id=\"genesis-content\").find(\"article\").find(\"div\").find_all(\"p\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "memes += [\" \".join(e.split(\" \")[1:]) for e in closed_ended[3:-5]]\n",
    "\n",
    "with open('memes.json', 'w') as outfile:\n",
    "    json.dump({\"memes\": memes}, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://conversationstartersworld.com/good-questions-to-ask/\"\n",
    "page = requests.get(URL)\n",
    "\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "good_question_to_ask = [e.text for e in soup.find(id=\"genesis-content\").find(\"article\").find(\"div\").find_all(\"p\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "memes += [\" \".join(e.split(\" \")[1:]) for e in good_question_to_ask[3:-5]]\n",
    "\n",
    "with open('memes.json', 'w') as outfile:\n",
    "    json.dump({\"memes\": memes}, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "URL = \"https://conversationstartersworld.com/250-conversation-starters/\"\n",
    "page = requests.get(URL)\n",
    "\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "ss = [e.text for e in soup.find(id=\"genesis-content\").find(\"article\").find(\"div\").find_all(\"p\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "memes += [\" \".join(e.split(\" \")[1:]) for e in ss[3:-5]]\n",
    "\n",
    "with open('memes.json', 'w') as outfile:\n",
    "    json.dump({\"memes\": memes}, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'generate-generalist-0.0.2.jsonl'\n",
    "with open(file_name, 'w') as outfile:\n",
    "    for meme in memes:\n",
    "        json.dump({\n",
    "            \"prompt\": \"\",\n",
    "            \"completion\": f\" {meme}\\n\\n\"\n",
    "        }, outfile)\n",
    "        outfile.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Upload progress: 100%|██████████| 250k/250k [00:00<00:00, 355kit/s]\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "f = openai.File.create(\n",
    "  file=open(file_name),\n",
    "  purpose=\"fine-tune\"\n",
    ")\n",
    "f_t = openai.FineTune.create(\n",
    "    training_file=f[\"id\"],\n",
    "    model=\"curie\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<FineTune fine-tune id=ft-eiaHkhbMgvOc3YL1SZL6bVV1 at 0x7fb3183235e0> JSON: {\n",
       "  \"created_at\": 1628408249,\n",
       "  \"fine_tuned_model\": \"curie:ft-beaumont-2021-08-08-08-14-15\",\n",
       "  \"hyperparams\": {\n",
       "    \"batch_size\": 4,\n",
       "    \"learning_rate_multiplier\": 0.1,\n",
       "    \"n_epochs\": 4,\n",
       "    \"prompt_loss_weight\": 0.1,\n",
       "    \"use_packing\": null\n",
       "  },\n",
       "  \"id\": \"ft-eiaHkhbMgvOc3YL1SZL6bVV1\",\n",
       "  \"model\": \"curie\",\n",
       "  \"object\": \"fine-tune\",\n",
       "  \"organization_id\": \"org-6iVquBDkjuvNsgZOGPJsaRAs\",\n",
       "  \"result_files\": [\n",
       "    {\n",
       "      \"bytes\": 98682,\n",
       "      \"created_at\": 1628410459,\n",
       "      \"filename\": \"compiled_results.csv\",\n",
       "      \"id\": \"file-UM4nGDiiDj52YCkEXLp7mb1F\",\n",
       "      \"model\": null,\n",
       "      \"object\": \"file\",\n",
       "      \"purpose\": \"fine-tune-results\",\n",
       "      \"status\": \"processed\",\n",
       "      \"status_details\": null\n",
       "    }\n",
       "  ],\n",
       "  \"status\": \"succeeded\",\n",
       "  \"training_files\": [\n",
       "    {\n",
       "      \"bytes\": 249406,\n",
       "      \"created_at\": 1628408248,\n",
       "      \"filename\": \"generate-generalist-0.0.3.jsonl\",\n",
       "      \"id\": \"file-qNSpkQUrHjgQH6dhihh35f54\",\n",
       "      \"model\": null,\n",
       "      \"object\": \"file\",\n",
       "      \"purpose\": \"fine-tune\",\n",
       "      \"status\": \"processed\",\n",
       "      \"status_details\": null\n",
       "    }\n",
       "  ],\n",
       "  \"updated_at\": 1628410462,\n",
       "  \"user_id\": \"user-fs8ZlgenluyrbB3JQwgRc7O8\",\n",
       "  \"validation_files\": []\n",
       "}"
      ]
     },
     "metadata": {},
     "execution_count": 85
    }
   ],
   "source": [
    "model = get_model_by_dataset_name(\"generate-generalist-0.0.3.jsonl\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(DatetimeWithNanoseconds(2021, 8, 8, 8, 16, 3, 347757, tzinfo=datetime.timezone.utc),\n <google.cloud.firestore_v1.document.DocumentReference object at 0x7fb2f2dbb2e0>)\n"
     ]
    }
   ],
   "source": [
    "p = {}\n",
    "p[\"type\"] = \"TopicGeneralistFineTuned3\"\n",
    "p[\"template\"] = \"[TOPIC]:\"\n",
    "t = {\n",
    "    \"createdAt\": firestore.SERVER_TIMESTAMP,\n",
    "    \"engine\": {\n",
    "        \"parameters\": {\n",
    "            \"model\": get_model_by_dataset_name(\"generate-generalist-0.0.3.jsonl\")[\"fine_tuned_model\"],\n",
    "            \"temperature\": 0.7,\n",
    "            \"maxTokens\": 150,\n",
    "            \"topP\": 1,\n",
    "            \"frequencyPenalty\": 0.1,\n",
    "            \"presencePenalty\": 0.1,\n",
    "            \"stop\": [\"\\n\\n\"],\n",
    "        }\n",
    "    }\n",
    "}\n",
    "p_col = langame_client._firestore_client.collection(\"prompts\")\n",
    "new_prompt_ref = p_col.add(p)\n",
    "pprint(p_col.document(new_prompt_ref[1].id).collection(\"tags\").add(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-3UYLNZzAyutQOqqva47e9mkN4H3LC at 0x7fb3182db540> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1628410869,\n",
       "  \"id\": \"cmpl-3UYLNZzAyutQOqqva47e9mkN4H3LC\",\n",
       "  \"model\": \"curie:ft-beaumont-2021-08-08-08-14-15\",\n",
       "  \"object\": \"text_completion\"\n",
       "}"
      ]
     },
     "metadata": {},
     "execution_count": 104
    }
   ],
   "source": [
    "openai.Completion.create(\n",
    "  model=model[\"fine_tuned_model\"],\n",
    "  prompt=\"This a conversation starter about philosophy:\",\n",
    "  max_tokens=300,\n",
    "  stop=[\"\\n\\n\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"classification-topic-endpoint-0.0.1.jsonl\"\n",
    "with open(file_name, 'w') as outfile:\n",
    "    for e in langame_client._firestore_client.collection(\"memes\").stream():\n",
    "        json.dump({\n",
    "            \"text\": e.get(\"content\"),\n",
    "            \"label\": e.get(\"topics\")[0]\n",
    "        }, outfile)\n",
    "        outfile.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Upload progress: 100%|██████████| 58.1k/58.1k [00:00<00:00, 104kit/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<File file id=file-rV9rZbiiziXLfjqc4MKLLChy at 0x7fb3187e4270> JSON: {\n",
       "  \"bytes\": 57821,\n",
       "  \"created_at\": 1628408105,\n",
       "  \"filename\": \"classification-topic-endpoint-0.0.1.jsonl\",\n",
       "  \"id\": \"file-rV9rZbiiziXLfjqc4MKLLChy\",\n",
       "  \"object\": \"file\",\n",
       "  \"purpose\": \"classifications\",\n",
       "  \"status\": \"uploaded\",\n",
       "  \"status_details\": null\n",
       "}"
      ]
     },
     "metadata": {},
     "execution_count": 77
    }
   ],
   "source": [
    "c_f = openai.File.create(\n",
    "    file=open(file_name),\n",
    "    purpose=\"classifications\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "InvalidRequestError",
     "evalue": "No similar documents were found in file with ID 'file-rV9rZbiiziXLfjqc4MKLLChy'.Please upload more documents or adjust your query.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4391/258186148.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m openai.Classification.create(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"file-rV9rZbiiziXLfjqc4MKLLChy\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"123\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msearch_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ada\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"curie\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.11/lib/python3.8/site-packages/openai/api_resources/classification.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, **params)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0minstance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"classifications\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.8.11/lib/python3.8/site-packages/openai/openai_object.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, stream, plain_old_data)\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0morganization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morganization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         )\n\u001b[0;32m--> 243\u001b[0;31m         response, stream, api_key = requestor.request(\n\u001b[0m\u001b[1;32m    244\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         )\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.11/lib/python3.8/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, stream)\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         )\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpret_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_api_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.11/lib/python3.8/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36minterpret_response\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    346\u001b[0m             )\n\u001b[1;32m    347\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpret_response_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minterpret_response_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.11/lib/python3.8/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36minterpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0mstream_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"error\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstream_error\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mrcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m             raise self.handle_error_response(\n\u001b[0m\u001b[1;32m    368\u001b[0m                 \u001b[0mrbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m             )\n",
      "\u001b[0;31mInvalidRequestError\u001b[0m: No similar documents were found in file with ID 'file-rV9rZbiiziXLfjqc4MKLLChy'.Please upload more documents or adjust your query."
     ]
    }
   ],
   "source": [
    "openai.Classification.create(\n",
    "    file=\"file-rV9rZbiiziXLfjqc4MKLLChy\",\n",
    "    query=\"123\",\n",
    "    search_model=\"ada\", \n",
    "    model=\"curie\", \n",
    "    max_examples=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Overview of Colaboratory Features",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('3.8.11')",
   "language": "python",
   "name": "python381164bit3811cb0aa0fea64b4b4783647945b1b9500c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}