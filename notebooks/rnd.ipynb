{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langame import LangameClient\n",
    "import numpy as np\n",
    "from autofaiss import build_index\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "from autofaiss import build_index\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "from langame.quality import is_garbage\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "c = LangameClient(path_to_config_file=\"../config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 10 existing conversation starters\n",
      "Preparing embeddings for existing conversation starters\n",
      "Loaded sentence embedding model, device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Unexpected segmentation fault encountered in worker.\n",
      "\u0000"
     ]
    }
   ],
   "source": [
    "firestore = c._firestore_client\n",
    "collection = firestore.collection(\"memes\").limit(10)\n",
    "existing_conversation_starters = []\n",
    "\n",
    "for e in collection.stream():\n",
    "    if is_garbage(e.to_dict()):\n",
    "        print(f\"Skipping id: {e.id}, garbage, data: {e.to_dict()},\")\n",
    "        continue\n",
    "    existing_conversation_starters.append({\"id\": e.id, **e.to_dict()})\n",
    "print(\n",
    "    f\"Got {len(existing_conversation_starters)} existing conversation starters\"\n",
    ")\n",
    "print(\"Preparing embeddings for existing conversation starters\")\n",
    "sentence_embeddings_model = None\n",
    "\n",
    "sentence_embeddings_model_name = \"sentence-transformers/LaBSE\"\n",
    "device = \"cpu\"\n",
    "\n",
    "print(f\"Loaded sentence embedding model, device: {device}\")\n",
    "\n",
    "sentence_embeddings_model = SentenceTransformer(\n",
    "    sentence_embeddings_model_name, device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [02:26, 14.68s/it]\n"
     ]
    }
   ],
   "source": [
    "bar = tqdm()\n",
    "embeddings = []\n",
    "for item in existing_conversation_starters:\n",
    "    emb = np.array(sentence_embeddings_model.encode(\n",
    "        item[\"content\"], show_progress_bar=False, device=device\n",
    "    ))\n",
    "\n",
    "    item[\"embedding\"] = emb\n",
    "    embeddings.append(emb)\n",
    "    bar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving embeddings to disk and building index to disk\n",
      "Using 16 omp threads (processes), consider increasing --nb_cores if you have more\n",
      "Launching the whole pipeline 01/29/2022, 10:01:39\n",
      "There are 10 embeddings of dim 768\n",
      "\tCompute estimated construction time of the index 01/29/2022, 10:01:39\n",
      "\t\t-> Train: 16.7 minutes\n",
      "\t\t-> Add: 0.0 seconds\n",
      "\t\tTotal: 16.7 minutes\n",
      "\t>>> Finished \"Compute estimated construction time of the index\" in 0.0001 secs\n",
      "\tChecking that your have enough memory available to create the index 01/29/2022, 10:01:39\n",
      "36.0KB of memory will be needed to build the index (more might be used if you have more)\n",
      "\t>>> Finished \"Checking that your have enough memory available to create the index\" in 0.0004 secs\n",
      "\tSelecting most promising index types given data characteristics 01/29/2022, 10:01:39\n",
      "\t>>> Finished \"Selecting most promising index types given data characteristics\" in 0.0000 secs\n",
      "\tCreating the index 01/29/2022, 10:01:39\n",
      "\t\t-> Instanciate the index Flat 01/29/2022, 10:01:39\n",
      "\t\t>>> Finished \"-> Instanciate the index Flat\" in 0.0013 secs\n",
      "The index size will be approximately 30.0KB\n",
      "The memory available for adding the vectors is 7.0GB(total available - used by the index)\n",
      "Will be using at most 1GB of ram for adding\n",
      "\t\t-> Adding the vectors to the index 01/29/2022, 10:01:39\n",
      "Using a batch size of 325520 (memory overhead 953.7MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 2240.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t>>> Finished \"-> Adding the vectors to the index\" in 0.0027 secs\n",
      "\t>>> Finished \"Creating the index\" in 0.0048 secs\n",
      "\tComputing best hyperparameters 01/29/2022, 10:01:39\n",
      "\t>>> Finished \"Computing best hyperparameters\" in 0.0000 secs\n",
      "The best hyperparameters are: \n",
      "\tCompute fast metrics 01/29/2022, 10:01:39\n",
      "2000\n",
      "\t>>> Finished \"Compute fast metrics\" in 0.0259 secs\n",
      "\tSaving the index on local disk 01/29/2022, 10:01:39\n",
      "\t>>> Finished \"Saving the index on local disk\" in 0.0005 secs\n",
      "Recap:\n",
      "{'99p_search_speed_ms': 0.014972963836044071,\n",
      " 'avg_search_speed_ms': 0.011739585548639297,\n",
      " 'compression ratio': 0.9985372988785958,\n",
      " 'index_key': 'Flat',\n",
      " 'index_param': '',\n",
      " 'nb vectors': 10,\n",
      " 'reconstruction error %': 0.0,\n",
      " 'size in bytes': 30765,\n",
      " 'vectors dimension': 768}\n",
      ">>> Finished \"Launching the whole pipeline\" in 0.0398 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/louis/Documents/langame-worker/env/lib/python3.8/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/louis/Documents/langame-worker/env/lib/python3.8/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/louis/Documents/langame-worker/env/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 677, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/home/louis/Documents/langame-worker/env/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1823, in _run_once\n",
      "    event_list = self._selector.select(timeout)\n",
      "  File \"/usr/lib/python3.8/selectors.py\", line 468, in select\n",
      "    fd_event_list = self._selector.poll(timeout, max_ev)\n",
      "  File \"/home/louis/Documents/langame-worker/env/lib/python3.8/site-packages/torch/utils/data/_utils/signal_handling.py\", line 66, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 1383963) is killed by signal: Segmentation fault. \n",
      "10it [00:44,  4.47s/it]\n"
     ]
    }
   ],
   "source": [
    "# delete \"embeddings\" and \"indexes\" folders\n",
    "for folder in [\"embeddings\", \"indexes\"]:\n",
    "    if os.path.exists(folder):\n",
    "        shutil.rmtree(folder)\n",
    "\n",
    "print(\"Saving embeddings to disk and building index to disk\")\n",
    "os.makedirs(\"embeddings\", exist_ok=True)\n",
    "np.save(\"embeddings/p1.npy\", embeddings)\n",
    "index, _ = build_index(\n",
    "    \"embeddings\",\n",
    "    index_path=\"indexes/knn.index\",\n",
    "    max_index_memory_usage=\"6G\",\n",
    "    current_memory_available=\"7G\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = sentence_embeddings_model.encode(\"intelligence\", show_progress_bar=False)\n",
    "_, I = index.search(np.array([query]), 20)\n",
    "memes = [memes_with_embedding[i][1] for i in I[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What is the mind?',\n",
       " 'Is artificial intelligence itself a species from the universe?',\n",
       " 'Would it be better to know less or more?',\n",
       " 'Do you think that there is a unique \"recipe\" for knowledge?',\n",
       " 'Do you think humans are the only intelligent life in the universe?',\n",
       " 'What do you know now that you wish you knew when you were younger?',\n",
       " 'Is it a possibility that the state become governed by an artificial intelligence?',\n",
       " 'What do you feel about consciousness, what does it mean to you?',\n",
       " 'Can science achieve its goal to give an explanation for everything?',\n",
       " 'Do you think technology will ever be able to \"understand\" (or model?) the human mind?',\n",
       " 'Does social status affect your intelligence?',\n",
       " 'Does mysticism play a role in the study of science ?',\n",
       " 'What if everything we knew was a lie?',\n",
       " 'What do you think about the \"knowledge economy\"?',\n",
       " 'How does knowledge affect our perception of the world?',\n",
       " 'What is knowledge?',\n",
       " 'What is your definition of intelligence?',\n",
       " \"Is human intelligence superior because of its ability to reason using logic ? Yet computers can also reason logically… However, they don't appear able think outside their programming/structure; whereas humans can spontaneously imagine new possibilities ... Can machines reach this highest possible level through continued evolution or will they always be limited by their structure just like animals are limited by theirs? Will AI ever reach consciousness , intuition , imagination …etc.? Do any computer programs currently exist which mimic the above characteristics enough so that people mistake them for human beings???\",\n",
       " 'What are the differences between human and machine intelligence?',\n",
       " 'Are robots really \"more\" intelligent than us? According to your understanding.']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set([e[\"content\"] for e in memes]))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "54cb2a04f1aaddec2e99139c9d7fdd1b3b41971afcbc7ceb72b4b8e2e31cae90"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
