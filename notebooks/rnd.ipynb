{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langame import LangameClient\n",
    "import numpy as np\n",
    "from autofaiss import build_index\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "from autofaiss import build_index\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "from langame.quality import is_garbage\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "c = LangameClient(path_to_config_file=\"../config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firestore = c._firestore_client\n",
    "collection = firestore.collection(\"memes\").limit(2000)\n",
    "existing_conversation_starters = []\n",
    "\n",
    "for e in collection.stream():\n",
    "    if is_garbage(e.to_dict()):\n",
    "        print(f\"Skipping id: {e.id}, garbage\")\n",
    "        continue\n",
    "    existing_conversation_starters.append({\"id\": e.id, **e.to_dict()})\n",
    "print(\n",
    "    f\"Got {len(existing_conversation_starters)} existing conversation starters\"\n",
    ")\n",
    "print(\"Preparing embeddings for existing conversation starters\")\n",
    "sentence_embeddings_model = None\n",
    "\n",
    "sentence_embeddings_model_name = \"sentence-transformers/LaBSE\"\n",
    "device = \"cpu\"\n",
    "\n",
    "print(f\"Loaded sentence embedding model, device: {device}\")\n",
    "\n",
    "sentence_embeddings_model = SentenceTransformer(\n",
    "    sentence_embeddings_model_name, device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [04:00, 60.05s/it]\n",
      "8it [00:23,  3.00s/it]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1970, 768)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bar = tqdm()\n",
    "embeddings = []\n",
    "batch_size = 256\n",
    "existing_conversation_starters_as_batch = [\n",
    "    [e[\"content\"] for e in existing_conversation_starters[i : i + batch_size]]\n",
    "    for i in range(0, len(existing_conversation_starters), batch_size)\n",
    "]\n",
    "for batch in existing_conversation_starters_as_batch:\n",
    "    emb = sentence_embeddings_model.encode(\n",
    "        batch,\n",
    "        show_progress_bar=False, device=device\n",
    "    )\n",
    "\n",
    "    # extends embeddings with batch\n",
    "    embeddings.extend(emb)\n",
    "    bar.update(1)\n",
    "# flatten embeddings\n",
    "embeddings = np.array(embeddings)\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving embeddings to disk and building index to disk\n",
      "Using 16 omp threads (processes), consider increasing --nb_cores if you have more\n",
      "Launching the whole pipeline 01/31/2022, 14:22:17\n",
      "There are 1970 embeddings of dim 768\n",
      "\tCompute estimated construction time of the index 01/31/2022, 14:22:17\n",
      "\t\t-> Train: 16.7 minutes\n",
      "\t\t-> Add: 0.0 seconds\n",
      "\t\tTotal: 16.7 minutes\n",
      "\t>>> Finished \"Compute estimated construction time of the index\" in 0.0001 secs\n",
      "\tChecking that your have enough memory available to create the index 01/31/2022, 14:22:17\n",
      "7.2MB of memory will be needed to build the index (more might be used if you have more)\n",
      "\t>>> Finished \"Checking that your have enough memory available to create the index\" in 0.0001 secs\n",
      "\tSelecting most promising index types given data characteristics 01/31/2022, 14:22:17\n",
      "\t>>> Finished \"Selecting most promising index types given data characteristics\" in 0.0000 secs\n",
      "\tCreating the index 01/31/2022, 14:22:17\n",
      "\t\t-> Instanciate the index HNSW15 01/31/2022, 14:22:17\n",
      "\t\t>>> Finished \"-> Instanciate the index HNSW15\" in 0.0008 secs\n",
      "The index size will be approximately 6.0MB\n",
      "The memory available for adding the vectors is 7.0GB(total available - used by the index)\n",
      "Will be using at most 1GB of ram for adding\n",
      "\t\t-> Adding the vectors to the index 01/31/2022, 14:22:17\n",
      "Using a batch size of 325520 (memory overhead 953.7MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 467.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t>>> Finished \"-> Adding the vectors to the index\" in 0.0489 secs\n",
      "\t>>> Finished \"Creating the index\" in 0.0506 secs\n",
      "\tComputing best hyperparameters 01/31/2022, 14:22:17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t>>> Finished \"Computing best hyperparameters\" in 13.3627 secs\n",
      "The best hyperparameters are: efSearch=14840\n",
      "\tCompute fast metrics 01/31/2022, 14:22:30\n",
      "1346\n",
      "\t>>> Finished \"Compute fast metrics\" in 10.0101 secs\n",
      "\tSaving the index on local disk 01/31/2022, 14:22:40\n",
      "\t>>> Finished \"Saving the index on local disk\" in 0.0036 secs\n",
      "Recap:\n",
      "{'99p_search_speed_ms': 30.27330986224115,\n",
      " 'avg_search_speed_ms': 7.430445420677548,\n",
      " 'compression ratio': 0.957607500296689,\n",
      " 'index_key': 'HNSW15',\n",
      " 'index_param': 'efSearch=14840',\n",
      " 'nb vectors': 1970,\n",
      " 'reconstruction error %': 0.0,\n",
      " 'size in bytes': 6319750,\n",
      " 'vectors dimension': 768}\n",
      ">>> Finished \"Launching the whole pipeline\" in 23.4371 secs\n"
     ]
    }
   ],
   "source": [
    "# delete \"embeddings\" and \"indexes\" folders\n",
    "for folder in [\"embeddings\", \"indexes\"]:\n",
    "    if os.path.exists(folder):\n",
    "        shutil.rmtree(folder)\n",
    "\n",
    "print(\"Saving embeddings to disk and building index to disk\")\n",
    "os.makedirs(\"embeddings\", exist_ok=True)\n",
    "np.save(\"embeddings/p1.npy\", embeddings)\n",
    "index, _ = build_index(\n",
    "    \"embeddings\",\n",
    "    index_path=\"indexes/knn.index\",\n",
    "    max_index_memory_usage=\"6G\",\n",
    "    current_memory_available=\"7G\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('If you could have been told something 10 years ago, what would you want to know?',\n",
       "  0.29374543),\n",
       " ('Does mysticism play a role in the study of science ?', 0.29662097),\n",
       " ('Is it a possibility that the state become governed by an artificial intelligence?',\n",
       "  0.29806253),\n",
       " ('Is it a possibility that the state become governed by an artificial intelligence?',\n",
       "  0.29806253),\n",
       " ('\"Describe Artificial Intelligence to me...\"', 0.29933268),\n",
       " ('Do you think technology will ever be able to \"understand\" (or model?) the human mind?',\n",
       "  0.3021911),\n",
       " ('Will artificial intelligence utilize self-awareness, in the form of consciousness?',\n",
       "  0.30300403),\n",
       " ('What is the mind?', 0.3038898),\n",
       " ('How does knowledge affect our perception of the world?', 0.30761823),\n",
       " ('What do you know now that you wish you knew when you were younger?',\n",
       "  0.3080268),\n",
       " ('Are robots really \"more\" intelligent than us? According to your understanding.',\n",
       "  0.30879834),\n",
       " ('How much does human intelligence actually matter?', 0.30906063),\n",
       " ('Can science one day explain why our brain gives us the ability to think?',\n",
       "  0.31067222),\n",
       " ('If you could know a secret, what would you wish to know?', 0.31182334),\n",
       " ('Do some people born intelligent and some smarter? Or it is other way around?',\n",
       "  0.3127006),\n",
       " ('Where does all intelligence originate from? Do you believe human Intelligence (or \"H\"I',\n",
       "  0.32047114),\n",
       " ('What is your definition of intelligence?', 0.32161498),\n",
       " ('What is the purpose of knowledge? Do you believe that queuing knowledge up in our brains makes us feel more intelligent?',\n",
       "  0.3301874),\n",
       " (\"What's the difference between knowledge, wisdom, and understanding?\",\n",
       "  0.37725076),\n",
       " ('What is knowledge?', 0.4488505)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = sentence_embeddings_model.encode(\"intelligence\", show_progress_bar=False)\n",
    "E, I = index.search(np.array([query]), 20)\n",
    "list(reversed([(existing_conversation_starters[i][\"content\"], E[0][idx_search]) for idx_search, i in enumerate(I[0])]))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "54cb2a04f1aaddec2e99139c9d7fdd1b3b41971afcbc7ceb72b4b8e2e31cae90"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
